{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2ca81225",
   "metadata": {},
   "source": [
    "## <i><u>HDFS COMMANDS:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a086814e",
   "metadata": {},
   "source": [
    "#### "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1650de42",
   "metadata": {},
   "source": [
    "### 1. List all HDFS Commands available with options"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cec46c51",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Usage: hadoop fs [generic options]\n",
      "\t[-appendToFile <localsrc> ... <dst>]\n",
      "\t[-cat [-ignoreCrc] <src> ...]\n",
      "\t[-checksum [-v] <src> ...]\n",
      "\t[-chgrp [-R] GROUP PATH...]\n",
      "\t[-chmod [-R] <MODE[,MODE]... | OCTALMODE> PATH...]\n",
      "\t[-chown [-R] [OWNER][:[GROUP]] PATH...]\n",
      "\t[-copyFromLocal [-f] [-p] [-l] [-d] [-t <thread count>] <localsrc> ... <dst>]\n",
      "\t[-copyToLocal [-f] [-p] [-ignoreCrc] [-crc] <src> ... <localdst>]\n",
      "\t[-count [-q] [-h] [-v] [-t [<storage type>]] [-u] [-x] [-e] <path> ...]\n",
      "\t[-cp [-f] [-p | -p[topax]] [-d] <src> ... <dst>]\n",
      "\t[-createSnapshot <snapshotDir> [<snapshotName>]]\n",
      "\t[-deleteSnapshot <snapshotDir> <snapshotName>]\n",
      "\t[-df [-h] [<path> ...]]\n",
      "\t[-du [-s] [-h] [-v] [-x] <path> ...]\n",
      "\t[-expunge [-immediate] [-fs <path>]]\n",
      "\t[-find <path> ... <expression> ...]\n",
      "\t[-get [-f] [-p] [-ignoreCrc] [-crc] <src> ... <localdst>]\n",
      "\t[-getfacl [-R] <path>]\n",
      "\t[-getfattr [-R] {-n name | -d} [-e en] <path>]\n",
      "\t[-getmerge [-nl] [-skip-empty-file] <src> <localdst>]\n",
      "\t[-head <file>]\n",
      "\t[-help [cmd ...]]\n",
      "\t[-ls [-C] [-d] [-h] [-q] [-R] [-t] [-S] [-r] [-u] [-e] [<path> ...]]\n",
      "\t[-mkdir [-p] <path> ...]\n",
      "\t[-moveFromLocal <localsrc> ... <dst>]\n",
      "\t[-moveToLocal <src> <localdst>]\n",
      "\t[-mv <src> ... <dst>]\n",
      "\t[-put [-f] [-p] [-l] [-d] <localsrc> ... <dst>]\n",
      "\t[-renameSnapshot <snapshotDir> <oldName> <newName>]\n",
      "\t[-rm [-f] [-r|-R] [-skipTrash] [-safely] <src> ...]\n",
      "\t[-rmdir [--ignore-fail-on-non-empty] <dir> ...]\n",
      "\t[-setfacl [-R] [{-b|-k} {-m|-x <acl_spec>} <path>]|[--set <acl_spec> <path>]]\n",
      "\t[-setfattr {-n name [-v value] | -x name} <path>]\n",
      "\t[-setrep [-R] [-w] <rep> <path> ...]\n",
      "\t[-stat [format] <path> ...]\n",
      "\t[-tail [-f] [-s <sleep interval>] <file>]\n",
      "\t[-test -[defswrz] <path>]\n",
      "\t[-text [-ignoreCrc] <src> ...]\n",
      "\t[-touch [-a] [-m] [-t TIMESTAMP ] [-c] <path> ...]\n",
      "\t[-touchz <path> ...]\n",
      "\t[-truncate [-w] <length> <path> ...]\n",
      "\t[-usage [cmd ...]]\n",
      "\n",
      "Generic options supported are:\n",
      "-conf <configuration file>        specify an application configuration file\n",
      "-D <property=value>               define a value for a given property\n",
      "-fs <file:///|hdfs://namenode:port> specify default filesystem URL to use, overrides 'fs.defaultFS' property from configurations.\n",
      "-jt <local|resourcemanager:port>  specify a ResourceManager\n",
      "-files <file1,...>                specify a comma-separated list of files to be copied to the map reduce cluster\n",
      "-libjars <jar1,...>               specify a comma-separated list of jar files to be included in the classpath\n",
      "-archives <archive1,...>          specify a comma-separated list of archives to be unarchived on the compute machines\n",
      "\n",
      "The general command line syntax is:\n",
      "command [genericOptions] [commandOptions]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!hdfs dfs "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4d77f97",
   "metadata": {},
   "source": [
    "#### "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "939bfbc7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Usage: hadoop fs [generic options]\n",
      "\t[-appendToFile <localsrc> ... <dst>]\n",
      "\t[-cat [-ignoreCrc] <src> ...]\n",
      "\t[-checksum [-v] <src> ...]\n",
      "\t[-chgrp [-R] GROUP PATH...]\n",
      "\t[-chmod [-R] <MODE[,MODE]... | OCTALMODE> PATH...]\n",
      "\t[-chown [-R] [OWNER][:[GROUP]] PATH...]\n",
      "\t[-copyFromLocal [-f] [-p] [-l] [-d] [-t <thread count>] <localsrc> ... <dst>]\n",
      "\t[-copyToLocal [-f] [-p] [-ignoreCrc] [-crc] <src> ... <localdst>]\n",
      "\t[-count [-q] [-h] [-v] [-t [<storage type>]] [-u] [-x] [-e] <path> ...]\n",
      "\t[-cp [-f] [-p | -p[topax]] [-d] <src> ... <dst>]\n",
      "\t[-createSnapshot <snapshotDir> [<snapshotName>]]\n",
      "\t[-deleteSnapshot <snapshotDir> <snapshotName>]\n",
      "\t[-df [-h] [<path> ...]]\n",
      "\t[-du [-s] [-h] [-v] [-x] <path> ...]\n",
      "\t[-expunge [-immediate] [-fs <path>]]\n",
      "\t[-find <path> ... <expression> ...]\n",
      "\t[-get [-f] [-p] [-ignoreCrc] [-crc] <src> ... <localdst>]\n",
      "\t[-getfacl [-R] <path>]\n",
      "\t[-getfattr [-R] {-n name | -d} [-e en] <path>]\n",
      "\t[-getmerge [-nl] [-skip-empty-file] <src> <localdst>]\n",
      "\t[-head <file>]\n",
      "\t[-help [cmd ...]]\n",
      "\t[-ls [-C] [-d] [-h] [-q] [-R] [-t] [-S] [-r] [-u] [-e] [<path> ...]]\n",
      "\t[-mkdir [-p] <path> ...]\n",
      "\t[-moveFromLocal <localsrc> ... <dst>]\n",
      "\t[-moveToLocal <src> <localdst>]\n",
      "\t[-mv <src> ... <dst>]\n",
      "\t[-put [-f] [-p] [-l] [-d] <localsrc> ... <dst>]\n",
      "\t[-renameSnapshot <snapshotDir> <oldName> <newName>]\n",
      "\t[-rm [-f] [-r|-R] [-skipTrash] [-safely] <src> ...]\n",
      "\t[-rmdir [--ignore-fail-on-non-empty] <dir> ...]\n",
      "\t[-setfacl [-R] [{-b|-k} {-m|-x <acl_spec>} <path>]|[--set <acl_spec> <path>]]\n",
      "\t[-setfattr {-n name [-v value] | -x name} <path>]\n",
      "\t[-setrep [-R] [-w] <rep> <path> ...]\n",
      "\t[-stat [format] <path> ...]\n",
      "\t[-tail [-f] [-s <sleep interval>] <file>]\n",
      "\t[-test -[defswrz] <path>]\n",
      "\t[-text [-ignoreCrc] <src> ...]\n",
      "\t[-touch [-a] [-m] [-t TIMESTAMP ] [-c] <path> ...]\n",
      "\t[-touchz <path> ...]\n",
      "\t[-truncate [-w] <length> <path> ...]\n",
      "\t[-usage [cmd ...]]\n",
      "\n",
      "Generic options supported are:\n",
      "-conf <configuration file>        specify an application configuration file\n",
      "-D <property=value>               define a value for a given property\n",
      "-fs <file:///|hdfs://namenode:port> specify default filesystem URL to use, overrides 'fs.defaultFS' property from configurations.\n",
      "-jt <local|resourcemanager:port>  specify a ResourceManager\n",
      "-files <file1,...>                specify a comma-separated list of files to be copied to the map reduce cluster\n",
      "-libjars <jar1,...>               specify a comma-separated list of jar files to be included in the classpath\n",
      "-archives <archive1,...>          specify a comma-separated list of archives to be unarchived on the compute machines\n",
      "\n",
      "The general command line syntax is:\n",
      "command [genericOptions] [commandOptions]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!hadoop fs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b091571",
   "metadata": {},
   "source": [
    "#### "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f0b5b3d",
   "metadata": {},
   "source": [
    "### 2. Get help for a particular command"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "8cb9beb3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-count [-q] [-h] [-v] [-t [<storage type>]] [-u] [-x] [-e] <path> ... :\n",
      "  Count the number of directories, files and bytes under the paths\n",
      "  that match the specified file pattern.  The output columns are:\n",
      "  DIR_COUNT FILE_COUNT CONTENT_SIZE PATHNAME\n",
      "  or, with the -q option:\n",
      "  QUOTA REM_QUOTA SPACE_QUOTA REM_SPACE_QUOTA\n",
      "        DIR_COUNT FILE_COUNT CONTENT_SIZE PATHNAME\n",
      "  The -h option shows file sizes in human readable format.\n",
      "  The -v option displays a header line.\n",
      "  The -x option excludes snapshots from being calculated. \n",
      "  The -t option displays quota by storage types.\n",
      "  It should be used with -q or -u option, otherwise it will be ignored.\n",
      "  If a comma-separated list of storage types is given after the -t option, \n",
      "  it displays the quota and usage for the specified types. \n",
      "  Otherwise, it displays the quota and usage for all the storage \n",
      "  types that support quota. The list of possible storage types(case insensitive):\n",
      "  ram_disk, ssd, disk and archive.\n",
      "  It can also pass the value '', 'all' or 'ALL' to specify all the storage types.\n",
      "  The -u option shows the quota and \n",
      "  the usage against the quota without the detailed content summary.The -e option\n",
      "  shows the erasure coding policy.\n"
     ]
    }
   ],
   "source": [
    "!hadoop fs -help count"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f785e84",
   "metadata": {},
   "source": [
    "#### "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5db32ff5",
   "metadata": {},
   "source": [
    "### 3. List files and directories available in HDFS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9c5a6996",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-ls [-C] [-d] [-h] [-q] [-R] [-t] [-S] [-r] [-u] [-e] [<path> ...] :\n",
      "  List the contents that match the specified file pattern. If path is not\n",
      "  specified, the contents of /user/<currentUser> will be listed. For a directory a\n",
      "  list of its direct children is returned (unless -d option is specified).\n",
      "  \n",
      "  Directory entries are of the form:\n",
      "  \tpermissions - userId groupId sizeOfDirectory(in bytes)\n",
      "  modificationDate(yyyy-MM-dd HH:mm) directoryName\n",
      "  \n",
      "  and file entries are of the form:\n",
      "  \tpermissions numberOfReplicas userId groupId sizeOfFile(in bytes)\n",
      "  modificationDate(yyyy-MM-dd HH:mm) fileName\n",
      "  \n",
      "    -C  Display the paths of files and directories only.\n",
      "    -d  Directories are listed as plain files.\n",
      "    -h  Formats the sizes of files in a human-readable fashion\n",
      "        rather than a number of bytes.\n",
      "    -q  Print ? instead of non-printable characters.\n",
      "    -R  Recursively list the contents of directories.\n",
      "    -t  Sort files by modification time (most recent first).\n",
      "    -S  Sort files by size.\n",
      "    -r  Reverse the order of the sort.\n",
      "    -u  Use time of last access instead of modification for\n",
      "        display and sorting.\n",
      "    -e  Display the erasure coding policy of files and directories.\n"
     ]
    }
   ],
   "source": [
    "!hadoop fs -help ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "686274c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2 items\n",
      "drwx------   - itv005077 supergroup          0 2023-04-15 10:10 .Trash\n",
      "-rw-r--r--   1 itv005077 supergroup  365001114 2023-04-15 10:57 bigLog.txt\n"
     ]
    }
   ],
   "source": [
    "!hadoop fs -ls "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "53568257",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2 items\n",
      "drwx------   - itv005077 supergroup          0 2023-04-15 10:10 /user/itv005077/.Trash\n",
      "-rw-r--r--   1 itv005077 supergroup  365001114 2023-04-15 10:57 /user/itv005077/bigLog.txt\n"
     ]
    }
   ],
   "source": [
    "!hadoop fs -ls /user/itv005077"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "323f02af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 32 items\n",
      "drwxr-xr-x   - hdfs  supergroup          0 2021-05-21 14:39 /customer_sel_col\n",
      "drwxr-xr-x   - hdfs  supergroup          0 2021-05-21 15:23 /customer_sel_col_fil\n",
      "-rwxrwxrwx   3 root  supergroup      85082 2021-05-21 16:57 /data\n",
      "-rw-r--r--   3 hdfs  supergroup        225 2022-12-23 02:25 /data.txt\n",
      "-rw-r--r--   3 hdfs  supergroup      85082 2021-09-21 16:07 /data_ankit\n",
      "drwxr-xr-x   - hdfs  supergroup          0 2022-12-18 05:26 /dir1\n",
      "drwxr-xr-x   - hbase supergroup          0 2023-02-15 08:17 /hbase\n",
      "drwxr-xr-x   - hdfs  supergroup          0 2022-07-18 06:19 /home\n",
      "drwxr-xr-x   - hdfs  supergroup          0 2021-08-13 23:47 /itv000273_data\n",
      "drwxr-xr-x   - hdfs  supergroup          0 2022-12-19 09:54 /new1\n",
      "drwxr-xr-x   - hdfs  supergroup          0 2022-12-18 05:15 /newd\n",
      "drwxr-xr-x   - hdfs  supergroup          0 2021-05-21 15:43 /order_no_pk_dir\n",
      "drwxr-xr-x   - hdfs  supergroup          0 2021-08-14 00:01 /order_results\n",
      "drwxr-xr-x   - hdfs  supergroup          0 2021-05-21 15:01 /orders_sel_col_fil\n",
      "drwxr-xr-x   - hdfs  supergroup          0 2021-05-21 15:11 /orders_sel_col_fil_eq\n",
      "drwxr-xr-x   - hdfs  supergroup          0 2021-05-17 21:16 /peopleresult\n",
      "drwxr-xr-x   - hdfs  supergroup          0 2022-08-12 02:40 /public\n",
      "drwxr-xr-x   - hdfs  supergroup          0 2021-05-17 22:59 /queryresult\n",
      "drwxr-xr-x   - hdfs  supergroup          0 2021-05-17 23:03 /queryresultBz\n",
      "drwxr-xr-x   - hdfs  supergroup          0 2021-05-21 16:26 /queryresult_new\n",
      "drwxr-xr-x   - hdfs  supergroup          0 2021-05-22 00:45 /queryresult_new1\n",
      "drwxr-xr-x   - hdfs  supergroup          0 2021-05-17 22:57 /queryresultsqoop-import\n",
      "drwxr-xr-x   - hdfs  supergroup          0 2020-12-29 01:52 /spark-jars\n",
      "drwxrwxrwx   - spark hadoop              0 2023-04-16 02:32 /spark-logs\n",
      "drwxr-xr-x   - hdfs  supergroup          0 2020-12-29 01:56 /spark2-jars\n",
      "drwxrwxrwx   - spark hadoop              0 2023-04-16 03:48 /spark2-logs\n",
      "drwxr-xr-x   - hdfs  supergroup          0 2022-02-04 09:03 /teja\n",
      "drwxr-xr-x   - hdfs  supergroup          0 2021-05-17 21:03 /testinh\n",
      "drwxrwxrwx   - hdfs  students            0 2023-04-15 02:50 /tmp\n",
      "drwxr-xr-x   - hdfs  supergroup          0 2023-04-15 22:00 /user\n",
      "drwxr-xr-x   - hdfs  supergroup          0 2021-09-21 16:24 /user1\n",
      "-rw-r--r--   3 hdfs  supergroup     170171 2022-12-18 02:48 /userr\n"
     ]
    }
   ],
   "source": [
    "!hadoop fs -ls /"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "57687fb6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 35 items\n",
      "drwxr-xr-x   - hdfs supergroup          0 2021-01-28 09:08 /public/Black_Friday\n",
      "drwxr-xr-x   - hdfs supergroup          0 2021-01-28 08:08 /public/Tableau\n",
      "drwxr-xr-x   - hdfs supergroup          0 2021-01-28 08:38 /public/Tableau_stocks\n",
      "drwxr-xr-x   - hdfs supergroup          0 2021-01-28 09:11 /public/TetrasoftBigDataHackathon\n",
      "drwxr-xr-x   - hdfs supergroup          0 2021-01-28 09:09 /public/addresses\n",
      "drwxr-xr-x   - hdfs supergroup          0 2021-01-28 08:04 /public/airlines_all\n",
      "drwxr-xr-x   - hdfs supergroup          0 2021-03-02 19:48 /public/airtraffic_all\n",
      "drwxr-xr-x   - hdfs supergroup          0 2021-01-28 08:02 /public/black_friday\n",
      "drwxr-xr-x   - hdfs supergroup          0 2021-01-28 09:04 /public/cards\n",
      "drwxr-xr-x   - hdfs supergroup          0 2021-01-28 09:13 /public/citibike\n",
      "drwxr-xr-x   - hdfs supergroup          0 2021-01-28 08:13 /public/connect-distributed-config\n",
      "drwxr-xr-x   - hdfs supergroup          0 2021-01-28 07:49 /public/covid19\n",
      "drwxr-xr-x   - hdfs supergroup          0 2021-01-28 08:08 /public/crime\n",
      "drwxr-xr-x   - hdfs supergroup          0 2021-02-15 00:15 /public/gharchive\n",
      "drwxr-xr-x   - hdfs supergroup          0 2021-01-28 11:39 /public/githubactivity\n",
      "drwxr-xr-x   - hdfs supergroup          0 2021-01-28 10:51 /public/h1b\n",
      "drwxr-xr-x   - hdfs supergroup          0 2021-01-28 10:46 /public/hr_db\n",
      "drwxr-xr-x   - hdfs supergroup          0 2021-01-28 10:43 /public/icds_poc\n",
      "drwxr-xr-x   - hdfs supergroup          0 2021-01-28 10:43 /public/markov_data\n",
      "drwxr-xr-x   - hdfs supergroup          0 2021-01-28 08:56 /public/mocktest\n",
      "drwxr-xr-x   - hdfs supergroup          0 2021-01-28 11:04 /public/nyse\n",
      "drwxr-xr-x   - hdfs supergroup          0 2021-01-28 08:11 /public/nyse_all\n",
      "drwxr-xr-x   - hdfs supergroup          0 2021-01-28 11:28 /public/nyse_seq\n",
      "drwxr-xr-x   - hdfs supergroup          0 2021-01-28 09:31 /public/nyse_symbols\n",
      "drwxr-xr-x   - hdfs supergroup          0 2021-04-29 03:04 /public/outbrain\n",
      "drwxr-xr-x   - hdfs supergroup          0 2021-01-28 11:29 /public/randomtextwriter\n",
      "drwxr-xr-x   - hdfs supergroup          0 2021-01-28 10:59 /public/randomtextwritercompressed\n",
      "drwxr-xr-x   - hdfs supergroup          0 2021-08-21 03:48 /public/retail_db\n",
      "drwxr-xr-x   - hdfs supergroup          0 2021-01-28 09:09 /public/retail_db_json\n",
      "drwxr-xr-x   - hdfs supergroup          0 2021-01-28 08:05 /public/sms\n",
      "drwxr-xr-x   - hdfs supergroup          0 2021-01-28 08:20 /public/used_vehicles\n",
      "drwxr-xr-x   - hdfs supergroup          0 2021-01-28 08:25 /public/weather\n",
      "drwxr-xr-x   - hdfs supergroup          0 2021-09-12 21:04 /public/wm_data\n",
      "drwxr-xr-x   - hdfs supergroup          0 2021-01-28 11:21 /public/yelp-dataset\n",
      "drwxr-xr-x   - hdfs supergroup          0 2021-01-28 11:26 /public/yelp-dataset-json\n"
     ]
    }
   ],
   "source": [
    "!hadoop fs -ls /public"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e46a4f23",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/public/Black_Friday\n",
      "/public/Tableau\n",
      "/public/Tableau_stocks\n",
      "/public/TetrasoftBigDataHackathon\n",
      "/public/addresses\n",
      "/public/airlines_all\n",
      "/public/airtraffic_all\n",
      "/public/black_friday\n",
      "/public/cards\n",
      "/public/citibike\n",
      "/public/connect-distributed-config\n",
      "/public/covid19\n",
      "/public/crime\n",
      "/public/gharchive\n",
      "/public/githubactivity\n",
      "/public/h1b\n",
      "/public/hr_db\n",
      "/public/icds_poc\n",
      "/public/markov_data\n",
      "/public/mocktest\n",
      "/public/nyse\n",
      "/public/nyse_all\n",
      "/public/nyse_seq\n",
      "/public/nyse_symbols\n",
      "/public/outbrain\n",
      "/public/randomtextwriter\n",
      "/public/randomtextwritercompressed\n",
      "/public/retail_db\n",
      "/public/retail_db_json\n",
      "/public/sms\n",
      "/public/used_vehicles\n",
      "/public/weather\n",
      "/public/wm_data\n",
      "/public/yelp-dataset\n",
      "/public/yelp-dataset-json\n"
     ]
    }
   ],
   "source": [
    "!hadoop fs -ls -C /public"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "08d3f3fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "drwxr-xr-x   - hdfs supergroup          0 2021-01-28 08:08 /public/Tableau\n"
     ]
    }
   ],
   "source": [
    "!hadoop fs -ls -d /public/Tableau"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "07bd4cc7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1 items\n",
      "-rw-r--r--   2 hdfs supergroup      3.7 M 2021-01-28 08:25 /public/weather/weather.csv\n"
     ]
    }
   ],
   "source": [
    "!hadoop fs -ls -h /public/weather"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "54d4210c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "drwxr-xr-x   - hdfs supergroup          0 2021-01-28 09:08 /public/crime/csv\n",
      "-rw-r--r--   2 hdfs supergroup 1505540526 2021-01-28 09:08 /public/crime/csv/crime_data.csv\n",
      "drwxr-xr-x   - hdfs supergroup          0 2021-01-28 08:07 /public/crime/json\n",
      "-rw-r--r--   2 hdfs supergroup 3096653703 2021-01-28 08:07 /public/crime/json/crime_data.json\n"
     ]
    }
   ],
   "source": [
    "!hadoop fs -ls -R /public/crime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "1e4ddba0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 35 items\n",
      "drwxr-xr-x   - hdfs supergroup          0 2021-09-12 21:04 /public/wm_data\n",
      "drwxr-xr-x   - hdfs supergroup          0 2021-08-21 03:48 /public/retail_db\n",
      "drwxr-xr-x   - hdfs supergroup          0 2021-04-29 03:04 /public/outbrain\n",
      "drwxr-xr-x   - hdfs supergroup          0 2021-03-02 19:48 /public/airtraffic_all\n",
      "drwxr-xr-x   - hdfs supergroup          0 2021-02-15 00:15 /public/gharchive\n",
      "drwxr-xr-x   - hdfs supergroup          0 2021-01-28 11:39 /public/githubactivity\n",
      "drwxr-xr-x   - hdfs supergroup          0 2021-01-28 11:29 /public/randomtextwriter\n",
      "drwxr-xr-x   - hdfs supergroup          0 2021-01-28 11:28 /public/nyse_seq\n",
      "drwxr-xr-x   - hdfs supergroup          0 2021-01-28 11:26 /public/yelp-dataset-json\n",
      "drwxr-xr-x   - hdfs supergroup          0 2021-01-28 11:21 /public/yelp-dataset\n",
      "drwxr-xr-x   - hdfs supergroup          0 2021-01-28 11:04 /public/nyse\n",
      "drwxr-xr-x   - hdfs supergroup          0 2021-01-28 10:59 /public/randomtextwritercompressed\n",
      "drwxr-xr-x   - hdfs supergroup          0 2021-01-28 10:51 /public/h1b\n",
      "drwxr-xr-x   - hdfs supergroup          0 2021-01-28 10:46 /public/hr_db\n",
      "drwxr-xr-x   - hdfs supergroup          0 2021-01-28 10:43 /public/markov_data\n",
      "drwxr-xr-x   - hdfs supergroup          0 2021-01-28 10:43 /public/icds_poc\n",
      "drwxr-xr-x   - hdfs supergroup          0 2021-01-28 09:31 /public/nyse_symbols\n",
      "drwxr-xr-x   - hdfs supergroup          0 2021-01-28 09:13 /public/citibike\n",
      "drwxr-xr-x   - hdfs supergroup          0 2021-01-28 09:11 /public/TetrasoftBigDataHackathon\n",
      "drwxr-xr-x   - hdfs supergroup          0 2021-01-28 09:09 /public/retail_db_json\n",
      "drwxr-xr-x   - hdfs supergroup          0 2021-01-28 09:09 /public/addresses\n",
      "drwxr-xr-x   - hdfs supergroup          0 2021-01-28 09:08 /public/Black_Friday\n",
      "drwxr-xr-x   - hdfs supergroup          0 2021-01-28 09:04 /public/cards\n",
      "drwxr-xr-x   - hdfs supergroup          0 2021-01-28 08:56 /public/mocktest\n",
      "drwxr-xr-x   - hdfs supergroup          0 2021-01-28 08:38 /public/Tableau_stocks\n",
      "drwxr-xr-x   - hdfs supergroup          0 2021-01-28 08:25 /public/weather\n",
      "drwxr-xr-x   - hdfs supergroup          0 2021-01-28 08:20 /public/used_vehicles\n",
      "drwxr-xr-x   - hdfs supergroup          0 2021-01-28 08:13 /public/connect-distributed-config\n",
      "drwxr-xr-x   - hdfs supergroup          0 2021-01-28 08:11 /public/nyse_all\n",
      "drwxr-xr-x   - hdfs supergroup          0 2021-01-28 08:08 /public/Tableau\n",
      "drwxr-xr-x   - hdfs supergroup          0 2021-01-28 08:08 /public/crime\n",
      "drwxr-xr-x   - hdfs supergroup          0 2021-01-28 08:05 /public/sms\n",
      "drwxr-xr-x   - hdfs supergroup          0 2021-01-28 08:04 /public/airlines_all\n",
      "drwxr-xr-x   - hdfs supergroup          0 2021-01-28 08:02 /public/black_friday\n",
      "drwxr-xr-x   - hdfs supergroup          0 2021-01-28 07:49 /public/covid19\n"
     ]
    }
   ],
   "source": [
    "!hadoop fs -ls -t /public"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "bca4ce3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 35 items\n",
      "drwxr-xr-x   - hdfs supergroup          0 2021-01-28 07:49 /public/covid19\n",
      "drwxr-xr-x   - hdfs supergroup          0 2021-01-28 08:02 /public/black_friday\n",
      "drwxr-xr-x   - hdfs supergroup          0 2021-01-28 08:04 /public/airlines_all\n",
      "drwxr-xr-x   - hdfs supergroup          0 2021-01-28 08:05 /public/sms\n",
      "drwxr-xr-x   - hdfs supergroup          0 2021-01-28 08:08 /public/crime\n",
      "drwxr-xr-x   - hdfs supergroup          0 2021-01-28 08:08 /public/Tableau\n",
      "drwxr-xr-x   - hdfs supergroup          0 2021-01-28 08:11 /public/nyse_all\n",
      "drwxr-xr-x   - hdfs supergroup          0 2021-01-28 08:13 /public/connect-distributed-config\n",
      "drwxr-xr-x   - hdfs supergroup          0 2021-01-28 08:20 /public/used_vehicles\n",
      "drwxr-xr-x   - hdfs supergroup          0 2021-01-28 08:25 /public/weather\n",
      "drwxr-xr-x   - hdfs supergroup          0 2021-01-28 08:38 /public/Tableau_stocks\n",
      "drwxr-xr-x   - hdfs supergroup          0 2021-01-28 08:56 /public/mocktest\n",
      "drwxr-xr-x   - hdfs supergroup          0 2021-01-28 09:04 /public/cards\n",
      "drwxr-xr-x   - hdfs supergroup          0 2021-01-28 09:08 /public/Black_Friday\n",
      "drwxr-xr-x   - hdfs supergroup          0 2021-01-28 09:09 /public/addresses\n",
      "drwxr-xr-x   - hdfs supergroup          0 2021-01-28 09:09 /public/retail_db_json\n",
      "drwxr-xr-x   - hdfs supergroup          0 2021-01-28 09:11 /public/TetrasoftBigDataHackathon\n",
      "drwxr-xr-x   - hdfs supergroup          0 2021-01-28 09:13 /public/citibike\n",
      "drwxr-xr-x   - hdfs supergroup          0 2021-01-28 09:31 /public/nyse_symbols\n",
      "drwxr-xr-x   - hdfs supergroup          0 2021-01-28 10:43 /public/icds_poc\n",
      "drwxr-xr-x   - hdfs supergroup          0 2021-01-28 10:43 /public/markov_data\n",
      "drwxr-xr-x   - hdfs supergroup          0 2021-01-28 10:46 /public/hr_db\n",
      "drwxr-xr-x   - hdfs supergroup          0 2021-01-28 10:51 /public/h1b\n",
      "drwxr-xr-x   - hdfs supergroup          0 2021-01-28 10:59 /public/randomtextwritercompressed\n",
      "drwxr-xr-x   - hdfs supergroup          0 2021-01-28 11:04 /public/nyse\n",
      "drwxr-xr-x   - hdfs supergroup          0 2021-01-28 11:21 /public/yelp-dataset\n",
      "drwxr-xr-x   - hdfs supergroup          0 2021-01-28 11:26 /public/yelp-dataset-json\n",
      "drwxr-xr-x   - hdfs supergroup          0 2021-01-28 11:28 /public/nyse_seq\n",
      "drwxr-xr-x   - hdfs supergroup          0 2021-01-28 11:29 /public/randomtextwriter\n",
      "drwxr-xr-x   - hdfs supergroup          0 2021-01-28 11:39 /public/githubactivity\n",
      "drwxr-xr-x   - hdfs supergroup          0 2021-02-15 00:15 /public/gharchive\n",
      "drwxr-xr-x   - hdfs supergroup          0 2021-03-02 19:48 /public/airtraffic_all\n",
      "drwxr-xr-x   - hdfs supergroup          0 2021-04-29 03:04 /public/outbrain\n",
      "drwxr-xr-x   - hdfs supergroup          0 2021-08-21 03:48 /public/retail_db\n",
      "drwxr-xr-x   - hdfs supergroup          0 2021-09-12 21:04 /public/wm_data\n"
     ]
    }
   ],
   "source": [
    "!hadoop fs -ls -t -r /public"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "3403dce9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 10 items\n",
      "-rw-r--r--   2 hdfs supergroup   29287790 2021-01-28 08:22 /public/addresses/Address-09.json\n",
      "-rw-r--r--   2 hdfs supergroup   29287626 2021-01-28 08:40 /public/addresses/Address-06.json\n",
      "-rw-r--r--   2 hdfs supergroup   29287469 2021-01-28 08:52 /public/addresses/Address-07.json\n",
      "-rw-r--r--   2 hdfs supergroup   29287048 2021-01-28 08:21 /public/addresses/Address-08.json\n",
      "-rw-r--r--   2 hdfs supergroup   29286563 2021-01-28 08:34 /public/addresses/Address-05.json\n",
      "-rw-r--r--   2 hdfs supergroup   29285388 2021-01-28 09:09 /public/addresses/Address-03.json\n",
      "-rw-r--r--   2 hdfs supergroup   29282913 2021-01-28 08:06 /public/addresses/Address-02.json\n",
      "-rw-r--r--   2 hdfs supergroup   29280780 2021-01-28 08:23 /public/addresses/Address-04.json\n",
      "-rw-r--r--   2 hdfs supergroup   29279265 2021-01-28 08:37 /public/addresses/Address-10.json\n",
      "-rw-r--r--   2 hdfs supergroup   29175117 2021-01-28 08:33 /public/addresses/Address-01.json\n"
     ]
    }
   ],
   "source": [
    "!hadoop fs -ls -S /public/addresses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "6fd6e83c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 10 items\n",
      "-rw-r--r--   2 hdfs supergroup   29175117 2021-01-28 08:33 /public/addresses/Address-01.json\n",
      "-rw-r--r--   2 hdfs supergroup   29279265 2021-01-28 08:37 /public/addresses/Address-10.json\n",
      "-rw-r--r--   2 hdfs supergroup   29280780 2021-01-28 08:23 /public/addresses/Address-04.json\n",
      "-rw-r--r--   2 hdfs supergroup   29282913 2021-01-28 08:06 /public/addresses/Address-02.json\n",
      "-rw-r--r--   2 hdfs supergroup   29285388 2021-01-28 09:09 /public/addresses/Address-03.json\n",
      "-rw-r--r--   2 hdfs supergroup   29286563 2021-01-28 08:34 /public/addresses/Address-05.json\n",
      "-rw-r--r--   2 hdfs supergroup   29287048 2021-01-28 08:21 /public/addresses/Address-08.json\n",
      "-rw-r--r--   2 hdfs supergroup   29287469 2021-01-28 08:52 /public/addresses/Address-07.json\n",
      "-rw-r--r--   2 hdfs supergroup   29287626 2021-01-28 08:40 /public/addresses/Address-06.json\n",
      "-rw-r--r--   2 hdfs supergroup   29287790 2021-01-28 08:22 /public/addresses/Address-09.json\n"
     ]
    }
   ],
   "source": [
    "!hadoop fs -ls -S -r /public/addresses"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be24275c",
   "metadata": {},
   "source": [
    "#### "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2402c24",
   "metadata": {},
   "source": [
    "### 4. Make directory in HDFS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "86be87fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-mkdir [-p] <path> ... :\n",
      "  Create a directory in specified location.\n",
      "                                                  \n",
      "  -p  Do not fail if the directory already exists \n"
     ]
    }
   ],
   "source": [
    "!hadoop fs -help mkdir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "8eda49e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "!hadoop fs -mkdir dir1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "30879358",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 3 items\n",
      "drwx------   - itv005077 supergroup          0 2023-04-15 10:10 .Trash\n",
      "-rw-r--r--   1 itv005077 supergroup  365001114 2023-04-15 10:57 bigLog.txt\n",
      "drwxr-xr-x   - itv005077 supergroup          0 2023-04-16 04:44 dir1\n"
     ]
    }
   ],
   "source": [
    "!hadoop fs -ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "545bb2a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "!hadoop fs -mkdir /user/itv005077/dir2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "a6a551ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 4 items\n",
      "drwx------   - itv005077 supergroup          0 2023-04-15 10:10 /user/itv005077/.Trash\n",
      "-rw-r--r--   1 itv005077 supergroup  365001114 2023-04-15 10:57 /user/itv005077/bigLog.txt\n",
      "drwxr-xr-x   - itv005077 supergroup          0 2023-04-16 04:44 /user/itv005077/dir1\n",
      "drwxr-xr-x   - itv005077 supergroup          0 2023-04-16 04:44 /user/itv005077/dir2\n"
     ]
    }
   ],
   "source": [
    "!hadoop fs -ls /user/itv005077"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "9a5abdbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "!hadoop fs -mkdir dir3 dir4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "4350f079",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 6 items\n",
      "drwx------   - itv005077 supergroup          0 2023-04-15 10:10 .Trash\n",
      "-rw-r--r--   1 itv005077 supergroup  365001114 2023-04-15 10:57 bigLog.txt\n",
      "drwxr-xr-x   - itv005077 supergroup          0 2023-04-16 04:44 dir1\n",
      "drwxr-xr-x   - itv005077 supergroup          0 2023-04-16 04:44 dir2\n",
      "drwxr-xr-x   - itv005077 supergroup          0 2023-04-16 04:45 dir3\n",
      "drwxr-xr-x   - itv005077 supergroup          0 2023-04-16 04:45 dir4\n"
     ]
    }
   ],
   "source": [
    "!hadoop fs -ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "9bc3b648",
   "metadata": {},
   "outputs": [],
   "source": [
    "!hadoop fs -mkdir /user/itv005077/dir5 dir6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "7a46c7f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 8 items\n",
      "drwx------   - itv005077 supergroup          0 2023-04-15 10:10 .Trash\n",
      "-rw-r--r--   1 itv005077 supergroup  365001114 2023-04-15 10:57 bigLog.txt\n",
      "drwxr-xr-x   - itv005077 supergroup          0 2023-04-16 04:44 dir1\n",
      "drwxr-xr-x   - itv005077 supergroup          0 2023-04-16 04:44 dir2\n",
      "drwxr-xr-x   - itv005077 supergroup          0 2023-04-16 04:45 dir3\n",
      "drwxr-xr-x   - itv005077 supergroup          0 2023-04-16 04:45 dir4\n",
      "drwxr-xr-x   - itv005077 supergroup          0 2023-04-16 04:45 dir5\n",
      "drwxr-xr-x   - itv005077 supergroup          0 2023-04-16 04:45 dir6\n"
     ]
    }
   ],
   "source": [
    "!hadoop fs -ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "ba48bb4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "!hadoop fs -mkdir -p data/retail_db/customers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "287a1383",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 9 items\n",
      "drwx------   - itv005077 supergroup          0 2023-04-15 10:10 .Trash\n",
      "-rw-r--r--   1 itv005077 supergroup  365001114 2023-04-15 10:57 bigLog.txt\n",
      "drwxr-xr-x   - itv005077 supergroup          0 2023-04-16 04:45 data\n",
      "drwxr-xr-x   - itv005077 supergroup          0 2023-04-16 04:44 dir1\n",
      "drwxr-xr-x   - itv005077 supergroup          0 2023-04-16 04:44 dir2\n",
      "drwxr-xr-x   - itv005077 supergroup          0 2023-04-16 04:45 dir3\n",
      "drwxr-xr-x   - itv005077 supergroup          0 2023-04-16 04:45 dir4\n",
      "drwxr-xr-x   - itv005077 supergroup          0 2023-04-16 04:45 dir5\n",
      "drwxr-xr-x   - itv005077 supergroup          0 2023-04-16 04:45 dir6\n"
     ]
    }
   ],
   "source": [
    "!hadoop fs -ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "acddf4f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1 items\n",
      "drwxr-xr-x   - itv005077 supergroup          0 2023-04-16 04:33 data/retail_db\n"
     ]
    }
   ],
   "source": [
    "!hadoop fs -ls data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "a7915bb9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1 items\n",
      "drwxr-xr-x   - itv005077 supergroup          0 2023-04-16 04:33 data/retail_db/customers\n"
     ]
    }
   ],
   "source": [
    "!hadoop fs -ls data/retail_db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "df9cc892",
   "metadata": {},
   "outputs": [],
   "source": [
    "!hadoop fs -ls data/retail_db/customers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "068b7c44",
   "metadata": {},
   "source": [
    "#### "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "7707ac25",
   "metadata": {},
   "outputs": [],
   "source": [
    "!hadoop fs -mkdir -p /user/itv005077/data/nyse_all/nyse_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "3342908a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2 items\n",
      "drwxr-xr-x   - itv005077 supergroup          0 2023-04-16 04:46 /user/itv005077/data/nyse_all\n",
      "drwxr-xr-x   - itv005077 supergroup          0 2023-04-16 04:45 /user/itv005077/data/retail_db\n"
     ]
    }
   ],
   "source": [
    "!hadoop fs -ls /user/itv005077/data/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "4bbd5b30",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1 items\n",
      "drwxr-xr-x   - itv005077 supergroup          0 2023-04-16 04:46 /user/itv005077/data/nyse_all/nyse_data\n"
     ]
    }
   ],
   "source": [
    "!hadoop fs -ls /user/itv005077/data/nyse_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "b0e02edf",
   "metadata": {},
   "outputs": [],
   "source": [
    "!hadoop fs -ls /user/itv005077/data/nyse_all/nyse_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbec0d48",
   "metadata": {},
   "source": [
    "#### "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5e0c6c4",
   "metadata": {},
   "source": [
    "### 5. Remove Empty Directories from HDFS "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "ab4b1914",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-rmdir [--ignore-fail-on-non-empty] <dir> ... :\n",
      "  Removes the directory entry specified by each directory argument, provided it is\n",
      "  empty.\n"
     ]
    }
   ],
   "source": [
    "!hadoop fs -help rmdir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "35f57375",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 9 items\n",
      "drwx------   - itv005077 supergroup          0 2023-04-15 10:10 .Trash\n",
      "-rw-r--r--   1 itv005077 supergroup  365001114 2023-04-16 04:54 bigLog.txt\n",
      "drwxr-xr-x   - itv005077 supergroup          0 2023-04-16 04:46 data\n",
      "drwxr-xr-x   - itv005077 supergroup          0 2023-04-16 04:44 dir1\n",
      "drwxr-xr-x   - itv005077 supergroup          0 2023-04-16 04:44 dir2\n",
      "drwxr-xr-x   - itv005077 supergroup          0 2023-04-16 04:45 dir3\n",
      "drwxr-xr-x   - itv005077 supergroup          0 2023-04-16 04:45 dir4\n",
      "drwxr-xr-x   - itv005077 supergroup          0 2023-04-16 04:45 dir5\n",
      "drwxr-xr-x   - itv005077 supergroup          0 2023-04-16 04:45 dir6\n"
     ]
    }
   ],
   "source": [
    "!hadoop fs -ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "36a3869b",
   "metadata": {},
   "outputs": [],
   "source": [
    "!hadoop fs -rmdir dir1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "6b196c38",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 8 items\n",
      "drwx------   - itv005077 supergroup          0 2023-04-15 10:10 .Trash\n",
      "-rw-r--r--   1 itv005077 supergroup  365001114 2023-04-16 04:54 bigLog.txt\n",
      "drwxr-xr-x   - itv005077 supergroup          0 2023-04-16 04:46 data\n",
      "drwxr-xr-x   - itv005077 supergroup          0 2023-04-16 04:44 dir2\n",
      "drwxr-xr-x   - itv005077 supergroup          0 2023-04-16 04:45 dir3\n",
      "drwxr-xr-x   - itv005077 supergroup          0 2023-04-16 04:45 dir4\n",
      "drwxr-xr-x   - itv005077 supergroup          0 2023-04-16 04:45 dir5\n",
      "drwxr-xr-x   - itv005077 supergroup          0 2023-04-16 04:45 dir6\n"
     ]
    }
   ],
   "source": [
    "!hadoop fs -ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "1065230e",
   "metadata": {},
   "outputs": [],
   "source": [
    "!hadoop fs -rmdir dir2 dir3 /user/itv005077/dir4 /user/itv005077/dir5 dir6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "48b717f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 3 items\n",
      "drwx------   - itv005077 supergroup          0 2023-04-15 10:10 .Trash\n",
      "-rw-r--r--   1 itv005077 supergroup  365001114 2023-04-16 04:54 bigLog.txt\n",
      "drwxr-xr-x   - itv005077 supergroup          0 2023-04-16 04:46 data\n"
     ]
    }
   ],
   "source": [
    "!hadoop fs -ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "f2884de5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rmdir: `data': Directory is not empty\n"
     ]
    }
   ],
   "source": [
    "!hadoop fs -rmdir data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "703df8a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "!hadoop fs -rmdir --ignore-fail-on-non-empty data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "0d0aad8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 3 items\n",
      "drwx------   - itv005077 supergroup          0 2023-04-15 10:10 .Trash\n",
      "-rw-r--r--   1 itv005077 supergroup  365001114 2023-04-16 04:54 bigLog.txt\n",
      "drwxr-xr-x   - itv005077 supergroup          0 2023-04-16 04:46 data\n"
     ]
    }
   ],
   "source": [
    "!hadoop fs -ls"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "532a7e4b",
   "metadata": {},
   "source": [
    "#### "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0489b53c",
   "metadata": {},
   "source": [
    "### 6. Remove Files/Directories from HDFS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "1dbbb5d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-rm [-f] [-r|-R] [-skipTrash] [-safely] <src> ... :\n",
      "  Delete all files that match the specified file pattern. Equivalent to the Unix\n",
      "  command \"rm <src>\"\n",
      "                                                                                 \n",
      "  -f          If the file does not exist, do not display a diagnostic message or \n",
      "              modify the exit status to reflect an error.                        \n",
      "  -[rR]       Recursively deletes directories.                                   \n",
      "  -skipTrash  option bypasses trash, if enabled, and immediately deletes <src>.  \n",
      "  -safely     option requires safety confirmation, if enabled, requires          \n",
      "              confirmation before deleting large directory with more than        \n",
      "              <hadoop.shell.delete.limit.num.files> files. Delay is expected when\n",
      "              walking over large directory recursively to count the number of    \n",
      "              files to be deleted before the confirmation.                       \n"
     ]
    }
   ],
   "source": [
    "!hadoop fs -help rm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "0eb3e816",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-04-16 05:11:00,203 INFO fs.TrashPolicyDefault: Moved: 'hdfs://m01.itversity.com:9000/user/itv005077/bigLog.txt' to trash at: hdfs://m01.itversity.com:9000/user/itv005077/.Trash/Current/user/itv005077/bigLog.txt1681636260176\n"
     ]
    }
   ],
   "source": [
    "!hadoop fs -rm bigLog.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "f5f30e43",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2 items\n",
      "drwx------   - itv005077 supergroup          0 2023-04-15 10:10 .Trash\n",
      "drwxr-xr-x   - itv005077 supergroup          0 2023-04-16 04:46 data\n"
     ]
    }
   ],
   "source": [
    "!hadoop fs -ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "8193f024",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-04-16 05:11:16,958 INFO fs.TrashPolicyDefault: Moved: 'hdfs://m01.itversity.com:9000/user/itv005077/data' to trash at: hdfs://m01.itversity.com:9000/user/itv005077/.Trash/Current/user/itv005077/data1681636276932\n"
     ]
    }
   ],
   "source": [
    "!hadoop fs -rm -r data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "93f44b30",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1 items\n",
      "drwx------   - itv005077 supergroup          0 2023-04-15 10:10 .Trash\n"
     ]
    }
   ],
   "source": [
    "!hadoop fs -ls"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b3b26fc",
   "metadata": {},
   "source": [
    "#### "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7682b93e",
   "metadata": {},
   "source": [
    "### 7. Copy Files/Directories from Local to HDFS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "417bb3c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-copyFromLocal [-f] [-p] [-l] [-d] [-t <thread count>] <localsrc> ... <dst> :\n",
      "  Copy files from the local file system into fs. Copying fails if the file already\n",
      "  exists, unless the -f flag is given.\n",
      "  Flags:\n",
      "                                                                                 \n",
      "  -p                 Preserves access and modification times, ownership and the  \n",
      "                     mode.                                                       \n",
      "  -f                 Overwrites the destination if it already exists.            \n",
      "  -t <thread count>  Number of threads to be used, default is 1.                 \n",
      "  -l                 Allow DataNode to lazily persist the file to disk. Forces   \n",
      "                     replication factor of 1. This flag will result in reduced   \n",
      "                     durability. Use with care.                                  \n",
      "  -d                 Skip creation of temporary file(<dst>._COPYING_).           \n"
     ]
    }
   ],
   "source": [
    "!hadoop fs -help copyFromLocal"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db05cd67",
   "metadata": {},
   "source": [
    "#### "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "56af65f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-put [-f] [-p] [-l] [-d] <localsrc> ... <dst> :\n",
      "  Copy files from the local file system into fs. Copying fails if the file already\n",
      "  exists, unless the -f flag is given.\n",
      "  Flags:\n",
      "                                                                       \n",
      "  -p  Preserves access and modification times, ownership and the mode. \n",
      "  -f  Overwrites the destination if it already exists.                 \n",
      "  -l  Allow DataNode to lazily persist the file to disk. Forces        \n",
      "         replication factor of 1. This flag will result in reduced\n",
      "         durability. Use with care.\n",
      "                                                        \n",
      "  -d  Skip creation of temporary file(<dst>._COPYING_). \n"
     ]
    }
   ],
   "source": [
    "!hadoop fs -help put"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b34a438",
   "metadata": {},
   "source": [
    "#### "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "4c7c5f5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 709640\n",
      "-rwxr-xr-x 1 root root 726663168 Jan 18  2017 largedeck.txt\n",
      "-rwxr-xr-x 1 root root       693 Feb 27  2017 smalldeck.txt\n"
     ]
    }
   ],
   "source": [
    "!ls -lrt /data/cards"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "1c75e5c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "!hadoop fs -copyFromLocal /data/cards/smalldeck.txt "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "cd88027e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2 items\n",
      "drwx------   - itv005077 supergroup          0 2023-04-15 10:10 .Trash\n",
      "-rw-r--r--   3 itv005077 supergroup        693 2023-04-16 05:16 smalldeck.txt\n"
     ]
    }
   ],
   "source": [
    "!hadoop fs -ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "d802a286",
   "metadata": {},
   "outputs": [],
   "source": [
    "!hadoop fs -copyFromLocal /data/cards/largedeck.txt /user/itv005077"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "789db450",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 3 items\n",
      "drwx------   - itv005077 supergroup          0 2023-04-15 10:10 .Trash\n",
      "-rw-r--r--   3 itv005077 supergroup  726663168 2023-04-16 05:18 largedeck.txt\n",
      "-rw-r--r--   3 itv005077 supergroup        693 2023-04-16 05:16 smalldeck.txt\n"
     ]
    }
   ],
   "source": [
    "!hadoop fs -ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "3043b5b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 285904\n",
      "-rwxr-xr-x 1 root root 29175117 Jul 18  2020 Address-01.json\n",
      "-rwxr-xr-x 1 root root 29282913 Jul 18  2020 Address-02.json\n",
      "-rwxr-xr-x 1 root root 29285388 Jul 18  2020 Address-03.json\n",
      "-rwxr-xr-x 1 root root 29280780 Jul 18  2020 Address-04.json\n",
      "-rwxr-xr-x 1 root root 29286563 Jul 18  2020 Address-05.json\n",
      "-rwxr-xr-x 1 root root 29287626 Jul 18  2020 Address-06.json\n",
      "-rwxr-xr-x 1 root root 29287469 Jul 18  2020 Address-07.json\n",
      "-rwxr-xr-x 1 root root 29287048 Jul 18  2020 Address-08.json\n",
      "-rwxr-xr-x 1 root root 29287790 Jul 18  2020 Address-09.json\n",
      "-rwxr-xr-x 1 root root 29279265 Jul 18  2020 Address-10.json\n"
     ]
    }
   ],
   "source": [
    "!ls -lrt /data/addresses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "5393ad1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "!hadoop fs -copyFromLocal /data/addresses/Address-01.json address_01_current.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "39bdc2c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 4 items\n",
      "drwx------   - itv005077 supergroup          0 2023-04-15 10:10 .Trash\n",
      "-rw-r--r--   3 itv005077 supergroup   29175117 2023-04-16 05:24 address.json\n",
      "-rw-r--r--   3 itv005077 supergroup  726663168 2023-04-16 05:18 largedeck.txt\n",
      "-rw-r--r--   3 itv005077 supergroup        693 2023-04-16 05:16 smalldeck.txt\n"
     ]
    }
   ],
   "source": [
    "!hadoop fs -ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "7ff4f2ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "copyFromLocal: User itv005077 is not a super user (non-super user cannot change owner).\n"
     ]
    }
   ],
   "source": [
    "!hadoop fs -copyFromLocal -p /data/addresses/Address-06.json address_06_preserved.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3b97eb52",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 5 items\n",
      "drwx------   - itv005077 supergroup          0 2023-04-15 10:10 .Trash\n",
      "-rw-r--r--   3 itv005077 supergroup   29175117 2023-04-16 05:26 address_01_current.json\n",
      "-rw-r--r--   3 itv005077 supergroup   29287626 2020-07-18 14:35 address_06_preserved.json\n",
      "-rw-r--r--   3 itv005077 supergroup  726663168 2023-04-16 05:18 largedeck.txt\n",
      "-rw-r--r--   3 itv005077 supergroup        693 2023-04-16 05:16 smalldeck.txt\n"
     ]
    }
   ],
   "source": [
    "!hadoop fs -ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "61a73a09",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "copyFromLocal: `address_01_current.json': File exists\n"
     ]
    }
   ],
   "source": [
    "!hadoop fs -copyFromLocal /data/addresses/Address-01.json address_01_current.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9d0cf758",
   "metadata": {},
   "outputs": [],
   "source": [
    "!hadoop fs -copyFromLocal -f /data/addresses/Address-01.json address_01_current.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "acfc6ca4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 5 items\n",
      "drwx------   - itv005077 supergroup          0 2023-04-15 10:10 .Trash\n",
      "-rw-r--r--   3 itv005077 supergroup   29175117 2023-04-16 07:34 address_01_current.json\n",
      "-rw-r--r--   3 itv005077 supergroup   29287626 2020-07-18 14:35 address_06_preserved.json\n",
      "-rw-r--r--   3 itv005077 supergroup  726663168 2023-04-16 05:18 largedeck.txt\n",
      "-rw-r--r--   3 itv005077 supergroup        693 2023-04-16 05:16 smalldeck.txt\n"
     ]
    }
   ],
   "source": [
    "!hadoop fs -ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1f9d4e10",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 8\n",
      "drwxr-xr-x 2 root root 4096 Apr  7  2019 nyse_data\n",
      "drwxr-xr-x 2 root root 4096 Apr  7  2019 nyse_stocks\n"
     ]
    }
   ],
   "source": [
    "!ls -l /data/nyse_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "40e9d37c",
   "metadata": {},
   "outputs": [],
   "source": [
    "!hadoop fs -copyFromLocal /data/nyse_all/ data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1339b483",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2 items\n",
      "drwxr-xr-x   - itv005077 supergroup          0 2023-04-16 07:43 data/nyse_data\n",
      "drwxr-xr-x   - itv005077 supergroup          0 2023-04-16 07:43 data/nyse_stocks\n"
     ]
    }
   ],
   "source": [
    "!hadoop fs -ls data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f190b0fd",
   "metadata": {},
   "source": [
    "#### "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3363f5cd",
   "metadata": {},
   "source": [
    "### 8. Move Files/Directories from Local to HDFS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2cd7f91d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-moveFromLocal <localsrc> ... <dst> :\n",
      "  Same as -put, except that the source is deleted after it's copied.\n"
     ]
    }
   ],
   "source": [
    "!hadoop fs -help moveFromLocal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "c87563ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 415600\n",
      "-rw-r--r-- 1 itv005077 students 365001114 Apr 16 04:53 bigLog.txt\n",
      "-rw-r--r-- 1 itv005077 students     79180 Apr 16 04:53 boringwords.txt\n",
      "-rw-r--r-- 1 itv005077 students    136855 Apr 16 04:53 customer-orders.csv\n",
      "-rw-r--r-- 1 itv005077 students      8254 Apr 16 04:53 friends-data.csv\n",
      "-rw-r--r-- 1 itv005077 students     95947 Apr 16 04:53 google-ads-data.csv\n",
      "-rw-r--r-- 1 itv005077 students      5812 Apr 16 07:48 kv1.txt\n",
      "-rw-r--r-- 1 itv005077 students       159 Apr 16 04:53 samplefile.txt\n",
      "-rw-r--r-- 1 itv005077 students     18322 Apr 16 04:53 search_data.txt\n",
      "-rwxr-xr-x 1 itv005077 students  60201900 Apr 16 04:53 students.csv\n"
     ]
    }
   ],
   "source": [
    "! ls -l ~/data/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "68a06176",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 6 items\n",
      "drwx------   - itv005077 supergroup          0 2023-04-15 10:10 .Trash\n",
      "-rw-r--r--   3 itv005077 supergroup   29175117 2023-04-16 07:34 address_01_current.json\n",
      "-rw-r--r--   3 itv005077 supergroup   29287626 2020-07-18 14:35 address_06_preserved.json\n",
      "drwxr-xr-x   - itv005077 supergroup          0 2023-04-16 07:43 data\n",
      "-rw-r--r--   3 itv005077 supergroup  726663168 2023-04-16 05:18 largedeck.txt\n",
      "-rw-r--r--   3 itv005077 supergroup        693 2023-04-16 05:16 smalldeck.txt\n"
     ]
    }
   ],
   "source": [
    "!hadoop fs -ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "d85a7dd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "!hadoop fs -moveFromLocal ~/data/kv1.txt "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "428b8198",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 7 items\n",
      "drwx------   - itv005077 supergroup          0 2023-04-15 10:10 .Trash\n",
      "-rw-r--r--   3 itv005077 supergroup   29175117 2023-04-16 07:34 address_01_current.json\n",
      "-rw-r--r--   3 itv005077 supergroup   29287626 2020-07-18 14:35 address_06_preserved.json\n",
      "drwxr-xr-x   - itv005077 supergroup          0 2023-04-16 07:43 data\n",
      "-rw-r--r--   3 itv005077 supergroup       5812 2023-04-16 07:48 kv1.txt\n",
      "-rw-r--r--   3 itv005077 supergroup  726663168 2023-04-16 05:18 largedeck.txt\n",
      "-rw-r--r--   3 itv005077 supergroup        693 2023-04-16 05:16 smalldeck.txt\n"
     ]
    }
   ],
   "source": [
    "!hadoop fs -ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "14844eca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 4\n",
      "drwxr-xr-x 2 itv005077 students 4096 Apr 16 07:53 sports\n"
     ]
    }
   ],
   "source": [
    "!ls -l ~/data_move"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "11f8cc25",
   "metadata": {},
   "outputs": [],
   "source": [
    "!hadoop fs -moveFromLocal ~/data_move"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "6cd9a336",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 8 items\n",
      "drwx------   - itv005077 supergroup          0 2023-04-15 10:10 .Trash\n",
      "-rw-r--r--   3 itv005077 supergroup   29175117 2023-04-16 07:34 address_01_current.json\n",
      "-rw-r--r--   3 itv005077 supergroup   29287626 2020-07-18 14:35 address_06_preserved.json\n",
      "drwxr-xr-x   - itv005077 supergroup          0 2023-04-16 07:43 data\n",
      "drwxr-xr-x   - itv005077 supergroup          0 2023-04-16 07:56 data_move\n",
      "-rw-r--r--   3 itv005077 supergroup       5812 2023-04-16 07:48 kv1.txt\n",
      "-rw-r--r--   3 itv005077 supergroup  726663168 2023-04-16 05:18 largedeck.txt\n",
      "-rw-r--r--   3 itv005077 supergroup        693 2023-04-16 05:16 smalldeck.txt\n"
     ]
    }
   ],
   "source": [
    "!hadoop fs -ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "1518db16",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1 items\n",
      "drwxr-xr-x   - itv005077 supergroup          0 2023-04-16 07:56 data_move/sports\n"
     ]
    }
   ],
   "source": [
    "!hadoop fs -ls data_move/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba6b3742",
   "metadata": {},
   "source": [
    "#### "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11ee7f0d",
   "metadata": {},
   "source": [
    "### 9. Copy Files/Directories from HDFS to Local"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "b124aaed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-copyToLocal [-f] [-p] [-ignoreCrc] [-crc] <src> ... <localdst> :\n",
      "  Identical to the -get command.\n"
     ]
    }
   ],
   "source": [
    "!hadoop fs -help copyToLocal"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d00dcb6a",
   "metadata": {},
   "source": [
    "#### "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "a86281a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-get [-f] [-p] [-ignoreCrc] [-crc] <src> ... <localdst> :\n",
      "  Copy files that match the file pattern <src> to the local name.  <src> is kept. \n",
      "  When copying multiple files, the destination must be a directory. Passing -f\n",
      "  overwrites the destination if it already exists and -p preserves access and\n",
      "  modification times, ownership and the mode.\n"
     ]
    }
   ],
   "source": [
    "!hadoop fs -help get"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "b4535cd8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 21 items\n",
      "-rw-r--r--   3 itv005077 supergroup    3842443 2023-04-16 07:43 data/nyse_data/NYSE_1997.txt.gz\n",
      "-rw-r--r--   3 itv005077 supergroup    4142942 2023-04-16 07:43 data/nyse_data/NYSE_1998.txt.gz\n",
      "-rw-r--r--   3 itv005077 supergroup    4297025 2023-04-16 07:43 data/nyse_data/NYSE_1999.txt.gz\n",
      "-rw-r--r--   3 itv005077 supergroup    4439306 2023-04-16 07:43 data/nyse_data/NYSE_2000.txt.gz\n",
      "-rw-r--r--   3 itv005077 supergroup    4722623 2023-04-16 07:43 data/nyse_data/NYSE_2001.txt.gz\n",
      "-rw-r--r--   3 itv005077 supergroup    5021940 2023-04-16 07:43 data/nyse_data/NYSE_2002.txt.gz\n",
      "-rw-r--r--   3 itv005077 supergroup    5271305 2023-04-16 07:43 data/nyse_data/NYSE_2003.txt.gz\n",
      "-rw-r--r--   3 itv005077 supergroup    5689069 2023-04-16 07:43 data/nyse_data/NYSE_2004.txt.gz\n",
      "-rw-r--r--   3 itv005077 supergroup    6207833 2023-04-16 07:43 data/nyse_data/NYSE_2005.txt.gz\n",
      "-rw-r--r--   3 itv005077 supergroup    6480175 2023-04-16 07:43 data/nyse_data/NYSE_2006.txt.gz\n",
      "-rw-r--r--   3 itv005077 supergroup    6903056 2023-04-16 07:43 data/nyse_data/NYSE_2007.txt.gz\n",
      "-rw-r--r--   3 itv005077 supergroup    7179621 2023-04-16 07:43 data/nyse_data/NYSE_2008.txt.gz\n",
      "-rw-r--r--   3 itv005077 supergroup    7186235 2023-04-16 07:43 data/nyse_data/NYSE_2009.txt.gz\n",
      "-rw-r--r--   3 itv005077 supergroup    7551218 2023-04-16 07:43 data/nyse_data/NYSE_2010.txt.gz\n",
      "-rw-r--r--   3 itv005077 supergroup    7980961 2023-04-16 07:43 data/nyse_data/NYSE_2011.txt.gz\n",
      "-rw-r--r--   3 itv005077 supergroup    8538688 2023-04-16 07:43 data/nyse_data/NYSE_2012.txt.gz\n",
      "-rw-r--r--   3 itv005077 supergroup    9588984 2023-04-16 07:43 data/nyse_data/NYSE_2013.txt.gz\n",
      "-rw-r--r--   3 itv005077 supergroup   10552757 2023-04-16 07:43 data/nyse_data/NYSE_2014.txt.gz\n",
      "-rw-r--r--   3 itv005077 supergroup   11327417 2023-04-16 07:43 data/nyse_data/NYSE_2015.txt.gz\n",
      "-rw-r--r--   3 itv005077 supergroup   11796756 2023-04-16 07:43 data/nyse_data/NYSE_2016.txt.gz\n",
      "-rw-r--r--   3 itv005077 supergroup     519586 2023-04-16 07:43 data/nyse_data/NYSE_2017.txt.gz\n"
     ]
    }
   ],
   "source": [
    "!hadoop fs -ls data/nyse_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "e098303a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 415592\n",
      "-rw-r--r-- 1 itv005077 students 365001114 Apr 16 04:53 bigLog.txt\n",
      "-rw-r--r-- 1 itv005077 students     79180 Apr 16 04:53 boringwords.txt\n",
      "-rw-r--r-- 1 itv005077 students    136855 Apr 16 04:53 customer-orders.csv\n",
      "-rw-r--r-- 1 itv005077 students      8254 Apr 16 04:53 friends-data.csv\n",
      "-rw-r--r-- 1 itv005077 students     95947 Apr 16 04:53 google-ads-data.csv\n",
      "-rw-r--r-- 1 itv005077 students       159 Apr 16 04:53 samplefile.txt\n",
      "-rw-r--r-- 1 itv005077 students     18322 Apr 16 04:53 search_data.txt\n",
      "-rwxr-xr-x 1 itv005077 students  60201900 Apr 16 04:53 students.csv\n"
     ]
    }
   ],
   "source": [
    "!ls -l ~/data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "c62ed220",
   "metadata": {},
   "outputs": [],
   "source": [
    "!hadoop fs -copyToLocal data/nyse_data/NYSE_2016.txt.gz ~/data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "cb89f2af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 427116\n",
      "-rw-r--r-- 1 itv005077 students 365001114 Apr 16 04:53 bigLog.txt\n",
      "-rw-r--r-- 1 itv005077 students     79180 Apr 16 04:53 boringwords.txt\n",
      "-rw-r--r-- 1 itv005077 students    136855 Apr 16 04:53 customer-orders.csv\n",
      "-rw-r--r-- 1 itv005077 students      8254 Apr 16 04:53 friends-data.csv\n",
      "-rw-r--r-- 1 itv005077 students     95947 Apr 16 04:53 google-ads-data.csv\n",
      "-rw-r--r-- 1 itv005077 students  11796756 Apr 16 08:04 NYSE_2016.txt.gz\n",
      "-rw-r--r-- 1 itv005077 students       159 Apr 16 04:53 samplefile.txt\n",
      "-rw-r--r-- 1 itv005077 students     18322 Apr 16 04:53 search_data.txt\n",
      "-rwxr-xr-x 1 itv005077 students  60201900 Apr 16 04:53 students.csv\n"
     ]
    }
   ],
   "source": [
    "!ls -l ~/data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "40e7849c",
   "metadata": {},
   "outputs": [],
   "source": [
    "!hadoop fs -copyToLocal data/nyse_data/NYSE_2016.txt.gz ~/data/copy.txt.gz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "470e2f90",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 438640\n",
      "-rw-r--r-- 1 itv005077 students  11796756 Apr 16 08:05 copy.txt.gz\n",
      "-rw-r--r-- 1 itv005077 students  11796756 Apr 16 08:04 NYSE_2016.txt.gz\n",
      "-rwxr-xr-x 1 itv005077 students  60201900 Apr 16 04:53 students.csv\n",
      "-rw-r--r-- 1 itv005077 students       159 Apr 16 04:53 samplefile.txt\n",
      "-rw-r--r-- 1 itv005077 students     18322 Apr 16 04:53 search_data.txt\n",
      "-rw-r--r-- 1 itv005077 students    136855 Apr 16 04:53 customer-orders.csv\n",
      "-rw-r--r-- 1 itv005077 students      8254 Apr 16 04:53 friends-data.csv\n",
      "-rw-r--r-- 1 itv005077 students     95947 Apr 16 04:53 google-ads-data.csv\n",
      "-rw-r--r-- 1 itv005077 students     79180 Apr 16 04:53 boringwords.txt\n",
      "-rw-r--r-- 1 itv005077 students 365001114 Apr 16 04:53 bigLog.txt\n"
     ]
    }
   ],
   "source": [
    "!ls -lt ~/data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "3ef38387",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2 items\n",
      "drwxr-xr-x   - itv005077 supergroup          0 2023-04-16 07:43 data/nyse_data\n",
      "drwxr-xr-x   - itv005077 supergroup          0 2023-04-16 07:43 data/nyse_stocks\n"
     ]
    }
   ],
   "source": [
    "!hadoop fs -ls data/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "6724c2b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "!hadoop fs -copyToLocal data/nyse_stocks ~/data/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "6bb19185",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 438644\n",
      "drwxr-xr-x 2 itv005077 students      4096 Apr 16 08:07 nyse_stocks\n",
      "-rw-r--r-- 1 itv005077 students  11796756 Apr 16 08:05 copy.txt.gz\n",
      "-rw-r--r-- 1 itv005077 students  11796756 Apr 16 08:04 NYSE_2016.txt.gz\n",
      "-rwxr-xr-x 1 itv005077 students  60201900 Apr 16 04:53 students.csv\n",
      "-rw-r--r-- 1 itv005077 students       159 Apr 16 04:53 samplefile.txt\n",
      "-rw-r--r-- 1 itv005077 students     18322 Apr 16 04:53 search_data.txt\n",
      "-rw-r--r-- 1 itv005077 students    136855 Apr 16 04:53 customer-orders.csv\n",
      "-rw-r--r-- 1 itv005077 students      8254 Apr 16 04:53 friends-data.csv\n",
      "-rw-r--r-- 1 itv005077 students     95947 Apr 16 04:53 google-ads-data.csv\n",
      "-rw-r--r-- 1 itv005077 students     79180 Apr 16 04:53 boringwords.txt\n",
      "-rw-r--r-- 1 itv005077 students 365001114 Apr 16 04:53 bigLog.txt\n"
     ]
    }
   ],
   "source": [
    "!ls -lt ~/data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc937674",
   "metadata": {},
   "source": [
    "#### "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94d157d3",
   "metadata": {},
   "source": [
    "### 10. Move File/Directories from HDFS to Local"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "92ee7fc3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-moveToLocal <src> <localdst> :\n",
      "  Not implemented yet\n"
     ]
    }
   ],
   "source": [
    "!hadoop fs -help moveToLocal"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcd78a32",
   "metadata": {},
   "source": [
    "#### "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "7fe673df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1 items\n",
      "drwxr-xr-x   - itv005077 supergroup          0 2023-04-16 07:56 data_move/sports\n"
     ]
    }
   ],
   "source": [
    "!hadoop fs -ls data_move/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "4c14372f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 438644\n",
      "drwxr-xr-x 2 itv005077 students      4096 Apr 16 08:07 nyse_stocks\n",
      "-rw-r--r-- 1 itv005077 students  11796756 Apr 16 08:05 copy.txt.gz\n",
      "-rw-r--r-- 1 itv005077 students  11796756 Apr 16 08:04 NYSE_2016.txt.gz\n",
      "-rwxr-xr-x 1 itv005077 students  60201900 Apr 16 04:53 students.csv\n",
      "-rw-r--r-- 1 itv005077 students       159 Apr 16 04:53 samplefile.txt\n",
      "-rw-r--r-- 1 itv005077 students     18322 Apr 16 04:53 search_data.txt\n",
      "-rw-r--r-- 1 itv005077 students    136855 Apr 16 04:53 customer-orders.csv\n",
      "-rw-r--r-- 1 itv005077 students      8254 Apr 16 04:53 friends-data.csv\n",
      "-rw-r--r-- 1 itv005077 students     95947 Apr 16 04:53 google-ads-data.csv\n",
      "-rw-r--r-- 1 itv005077 students     79180 Apr 16 04:53 boringwords.txt\n",
      "-rw-r--r-- 1 itv005077 students 365001114 Apr 16 04:53 bigLog.txt\n"
     ]
    }
   ],
   "source": [
    "!ls -lt ~/data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "e23dda14",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "moveToLocal: Option '-moveToLocal' is not implemented yet.\n"
     ]
    }
   ],
   "source": [
    "!hadoop fs -moveToLocal data_move/sports ~/data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "1db01256",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 438644\n",
      "drwxr-xr-x 2 itv005077 students      4096 Apr 16 08:07 nyse_stocks\n",
      "-rw-r--r-- 1 itv005077 students  11796756 Apr 16 08:05 copy.txt.gz\n",
      "-rw-r--r-- 1 itv005077 students  11796756 Apr 16 08:04 NYSE_2016.txt.gz\n",
      "-rwxr-xr-x 1 itv005077 students  60201900 Apr 16 04:53 students.csv\n",
      "-rw-r--r-- 1 itv005077 students       159 Apr 16 04:53 samplefile.txt\n",
      "-rw-r--r-- 1 itv005077 students     18322 Apr 16 04:53 search_data.txt\n",
      "-rw-r--r-- 1 itv005077 students    136855 Apr 16 04:53 customer-orders.csv\n",
      "-rw-r--r-- 1 itv005077 students      8254 Apr 16 04:53 friends-data.csv\n",
      "-rw-r--r-- 1 itv005077 students     95947 Apr 16 04:53 google-ads-data.csv\n",
      "-rw-r--r-- 1 itv005077 students     79180 Apr 16 04:53 boringwords.txt\n",
      "-rw-r--r-- 1 itv005077 students 365001114 Apr 16 04:53 bigLog.txt\n"
     ]
    }
   ],
   "source": [
    "!ls -lt ~/data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9df7265c",
   "metadata": {},
   "source": [
    "#### "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75fd44c7",
   "metadata": {},
   "source": [
    "### 11. Copy Files/Folders in HDFS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "84296521",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-cp [-f] [-p | -p[topax]] [-d] <src> ... <dst> :\n",
      "  Copy files that match the file pattern <src> to a destination.  When copying\n",
      "  multiple files, the destination must be a directory. Passing -p preserves status\n",
      "  [topax] (timestamps, ownership, permission, ACLs, XAttr). If -p is specified\n",
      "  with no <arg>, then preserves timestamps, ownership, permission. If -pa is\n",
      "  specified, then preserves permission also because ACL is a super-set of\n",
      "  permission. Passing -f overwrites the destination if it already exists. raw\n",
      "  namespace extended attributes are preserved if (1) they are supported (HDFS\n",
      "  only) and, (2) all of the source and target pathnames are in the /.reserved/raw\n",
      "  hierarchy. raw namespace xattr preservation is determined solely by the presence\n",
      "  (or absence) of the /.reserved/raw prefix and not by the -p option. Passing -d\n",
      "  will skip creation of temporary file(<dst>._COPYING_).\n"
     ]
    }
   ],
   "source": [
    "!hadoop fs -help cp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "4362e232",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1 items\n",
      "-rw-r--r--   3 itv005077 supergroup       1226 2023-04-16 07:56 data_move/sports/famous_players.json\n"
     ]
    }
   ],
   "source": [
    "!hadoop fs -ls data_move/sports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "325749ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 8 items\n",
      "drwx------   - itv005077 supergroup          0 2023-04-15 10:10 .Trash\n",
      "-rw-r--r--   3 itv005077 supergroup   29175117 2023-04-16 07:34 address_01_current.json\n",
      "-rw-r--r--   3 itv005077 supergroup   29287626 2020-07-18 14:35 address_06_preserved.json\n",
      "drwxr-xr-x   - itv005077 supergroup          0 2023-04-16 07:43 data\n",
      "drwxr-xr-x   - itv005077 supergroup          0 2023-04-16 07:56 data_move\n",
      "-rw-r--r--   3 itv005077 supergroup       5812 2023-04-16 07:48 kv1.txt\n",
      "-rw-r--r--   3 itv005077 supergroup  726663168 2023-04-16 05:18 largedeck.txt\n",
      "-rw-r--r--   3 itv005077 supergroup        693 2023-04-16 05:16 smalldeck.txt\n"
     ]
    }
   ],
   "source": [
    "!hadoop fs -ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "710fba33",
   "metadata": {},
   "outputs": [],
   "source": [
    "!hadoop fs -cp data_move/sports/famous_players.json ./"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "2d0687dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 9 items\n",
      "-rw-r--r--   3 itv005077 supergroup       1226 2023-04-16 08:16 famous_players.json\n",
      "drwxr-xr-x   - itv005077 supergroup          0 2023-04-16 07:56 data_move\n",
      "-rw-r--r--   3 itv005077 supergroup       5812 2023-04-16 07:48 kv1.txt\n",
      "drwxr-xr-x   - itv005077 supergroup          0 2023-04-16 07:43 data\n",
      "-rw-r--r--   3 itv005077 supergroup   29175117 2023-04-16 07:34 address_01_current.json\n",
      "-rw-r--r--   3 itv005077 supergroup  726663168 2023-04-16 05:18 largedeck.txt\n",
      "-rw-r--r--   3 itv005077 supergroup        693 2023-04-16 05:16 smalldeck.txt\n",
      "drwx------   - itv005077 supergroup          0 2023-04-15 10:10 .Trash\n",
      "-rw-r--r--   3 itv005077 supergroup   29287626 2020-07-18 14:35 address_06_preserved.json\n"
     ]
    }
   ],
   "source": [
    "!hadoop fs -ls -t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "1b47773e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2 items\n",
      "drwxr-xr-x   - itv005077 supergroup          0 2023-04-16 07:43 data/nyse_data\n",
      "drwxr-xr-x   - itv005077 supergroup          0 2023-04-16 07:43 data/nyse_stocks\n"
     ]
    }
   ],
   "source": [
    "!hadoop fs -ls data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "0f969099",
   "metadata": {},
   "outputs": [],
   "source": [
    "!hadoop fs -cp -f largedeck.txt smalldeck.txt data/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "7ac9ac60",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 4 items\n",
      "-rw-r--r--   3 itv005077 supergroup        693 2023-04-16 08:20 data/smalldeck.txt\n",
      "-rw-r--r--   3 itv005077 supergroup  726663168 2023-04-16 08:20 data/largedeck.txt\n",
      "drwxr-xr-x   - itv005077 supergroup          0 2023-04-16 07:43 data/nyse_data\n",
      "drwxr-xr-x   - itv005077 supergroup          0 2023-04-16 07:43 data/nyse_stocks\n"
     ]
    }
   ],
   "source": [
    "!hadoop fs -ls -t data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7179f0bd",
   "metadata": {},
   "source": [
    "#### "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eaa5f078",
   "metadata": {},
   "source": [
    "### 12. Move Files/Folders in HDFS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "af9d3d7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-mv <src> ... <dst> :\n",
      "  Move files that match the specified file pattern <src> to a destination <dst>. \n",
      "  When moving multiple files, the destination must be a directory.\n"
     ]
    }
   ],
   "source": [
    "!hadoop fs -help mv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "b870d299",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1 items\n",
      "drwxr-xr-x   - itv005077 supergroup          0 2023-04-16 07:56 data_move/sports\n"
     ]
    }
   ],
   "source": [
    "!hadoop fs -ls data_move/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "54553d79",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 4 items\n",
      "-rw-r--r--   3 itv005077 supergroup  726663168 2023-04-16 08:20 data/largedeck.txt\n",
      "drwxr-xr-x   - itv005077 supergroup          0 2023-04-16 07:43 data/nyse_data\n",
      "drwxr-xr-x   - itv005077 supergroup          0 2023-04-16 07:43 data/nyse_stocks\n",
      "-rw-r--r--   3 itv005077 supergroup        693 2023-04-16 08:20 data/smalldeck.txt\n"
     ]
    }
   ],
   "source": [
    "!hadoop fs -ls data/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "a019fac0",
   "metadata": {},
   "outputs": [],
   "source": [
    "!hadoop fs -mv data/smalldeck.txt data_move/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "0d7857d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2 items\n",
      "-rw-r--r--   3 itv005077 supergroup        693 2023-04-16 08:20 data_move/smalldeck.txt\n",
      "drwxr-xr-x   - itv005077 supergroup          0 2023-04-16 07:56 data_move/sports\n"
     ]
    }
   ],
   "source": [
    "!hadoop fs -ls -t data_move/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "1fbbe2be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 3 items\n",
      "-rw-r--r--   3 itv005077 supergroup  726663168 2023-04-16 08:20 data/largedeck.txt\n",
      "drwxr-xr-x   - itv005077 supergroup          0 2023-04-16 07:43 data/nyse_data\n",
      "drwxr-xr-x   - itv005077 supergroup          0 2023-04-16 07:43 data/nyse_stocks\n"
     ]
    }
   ],
   "source": [
    "!hadoop fs -ls data/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "26682128",
   "metadata": {},
   "outputs": [],
   "source": [
    "!hadoop fs -mv data/nyse_stocks data_move"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "482b950a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 3 items\n",
      "drwxr-xr-x   - itv005077 supergroup          0 2023-04-16 07:43 data_move/nyse_stocks\n",
      "-rw-r--r--   3 itv005077 supergroup        693 2023-04-16 08:20 data_move/smalldeck.txt\n",
      "drwxr-xr-x   - itv005077 supergroup          0 2023-04-16 07:56 data_move/sports\n"
     ]
    }
   ],
   "source": [
    "!hadoop fs -ls data_move/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "1c7f4916",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2 items\n",
      "-rw-r--r--   3 itv005077 supergroup  726663168 2023-04-16 08:20 data/largedeck.txt\n",
      "drwxr-xr-x   - itv005077 supergroup          0 2023-04-16 07:43 data/nyse_data\n"
     ]
    }
   ],
   "source": [
    "!hadoop fs -ls data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32ab722b",
   "metadata": {},
   "source": [
    "#### "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9388bfe4",
   "metadata": {},
   "source": [
    "### 13. Change Permission of Files/Directories in HDFS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "bb48bb76",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 9 items\n",
      "drwx------   - itv005077 supergroup          0 2023-04-15 10:10 .Trash\n",
      "-rw-r--r--   3 itv005077 supergroup   29175117 2023-04-16 07:34 address_01_current.json\n",
      "-rw-r--r--   3 itv005077 supergroup   29287626 2020-07-18 14:35 address_06_preserved.json\n",
      "drwxr-xr-x   - itv005077 supergroup          0 2023-04-16 08:25 data\n",
      "drwxr-xr-x   - itv005077 supergroup          0 2023-04-16 08:25 data_move\n",
      "-rw-r--r--   3 itv005077 supergroup       1226 2023-04-16 08:16 famous_players.json\n",
      "-rw-r--r--   3 itv005077 supergroup       5812 2023-04-16 07:48 kv1.txt\n",
      "-rw-r--r--   3 itv005077 supergroup  726663168 2023-04-16 05:18 largedeck.txt\n",
      "-rw-r--r--   3 itv005077 supergroup        693 2023-04-16 05:16 smalldeck.txt\n"
     ]
    }
   ],
   "source": [
    "!hadoop fs -ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "230a5055",
   "metadata": {},
   "outputs": [],
   "source": [
    "!hadoop fs -chmod 444 address_01_current.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "4fd61fd5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 9 items\n",
      "drwx------   - itv005077 supergroup          0 2023-04-15 10:10 .Trash\n",
      "-r--r--r--   3 itv005077 supergroup   29175117 2023-04-16 07:34 address_01_current.json\n",
      "-rw-r--r--   3 itv005077 supergroup   29287626 2020-07-18 14:35 address_06_preserved.json\n",
      "drwxr-xr-x   - itv005077 supergroup          0 2023-04-16 08:25 data\n",
      "drwxr-xr-x   - itv005077 supergroup          0 2023-04-16 08:25 data_move\n",
      "-rw-r--r--   3 itv005077 supergroup       1226 2023-04-16 08:16 famous_players.json\n",
      "-rw-r--r--   3 itv005077 supergroup       5812 2023-04-16 07:48 kv1.txt\n",
      "-rw-r--r--   3 itv005077 supergroup  726663168 2023-04-16 05:18 largedeck.txt\n",
      "-rw-r--r--   3 itv005077 supergroup        693 2023-04-16 05:16 smalldeck.txt\n"
     ]
    }
   ],
   "source": [
    "!hadoop fs -ls"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64d3d34e",
   "metadata": {},
   "source": [
    "#### "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54ae31fd",
   "metadata": {},
   "source": [
    "### 14. Fetch First few lines (1KB) of a file in HDFS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "fe755ec3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-head <file> :\n",
      "  Show the first 1KB of the file.\n"
     ]
    }
   ],
   "source": [
    "!hadoop fs -help head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "7d111e6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BLACK|SPADE|2\n",
      "BLACK|SPADE|3\n",
      "BLACK|SPADE|4\n",
      "BLACK|SPADE|5\n",
      "BLACK|SPADE|6\n",
      "BLACK|SPADE|7\n",
      "BLACK|SPADE|8\n",
      "BLACK|SPADE|9\n",
      "BLACK|SPADE|10\n",
      "BLACK|SPADE|J\n",
      "BLACK|SPADE|Q\n",
      "BLACK|SPADE|K\n",
      "BLACK|SPADE|A\n",
      "BLACK|CLUB|2\n",
      "BLACK|CLUB|3\n",
      "BLACK|CLUB|4\n",
      "BLACK|CLUB|5\n",
      "BLACK|CLUB|6\n",
      "BLACK|CLUB|7\n",
      "BLACK|CLUB|8\n",
      "BLACK|CLUB|9\n",
      "BLACK|CLUB|10\n",
      "BLACK|CLUB|J\n",
      "BLACK|CLUB|Q\n",
      "BLACK|CLUB|K\n",
      "BLACK|CLUB|A\n",
      "RED|DIAMOND|2\n",
      "RED|DIAMOND|3\n",
      "RED|DIAMOND|4\n",
      "RED|DIAMOND|5\n",
      "RED|DIAMOND|6\n",
      "RED|DIAMOND|7\n",
      "RED|DIAMOND|8\n",
      "RED|DIAMOND|9\n",
      "RED|DIAMOND|10\n",
      "RED|DIAMOND|J\n",
      "RED|DIAMOND|Q\n",
      "RED|DIAMOND|K\n",
      "RED|DIAMOND|A\n",
      "RED|HEART|2\n",
      "RED|HEART|3\n",
      "RED|HEART|4\n",
      "RED|HEART|5\n",
      "RED|HEART|6\n",
      "RED|HEART|7\n",
      "RED|HEART|8\n",
      "RED|HEART|9\n",
      "RED|HEART|10\n",
      "RED|HEART|J\n",
      "RED|HEART|Q\n",
      "RED|HEART|K\n",
      "RED|HEART|A\n"
     ]
    }
   ],
   "source": [
    "!hadoop fs -head smalldeck.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5700f52",
   "metadata": {},
   "source": [
    "#### "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c68abb0",
   "metadata": {},
   "source": [
    "### 15. Fetch Last few lines (1KB) of a file in HDFS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "774b0ad4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-tail [-f] [-s <sleep interval>] <file> :\n",
      "  Show the last 1KB of the file.\n",
      "                                                                               \n",
      "  -f  Shows appended data as the file grows.                                   \n",
      "  -s  With -f , defines the sleep interval between iterations in milliseconds. \n"
     ]
    }
   ],
   "source": [
    "!hadoop fs -help tail"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "26b3c682",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "    {\n",
      "        \"name\": \"Brian Lara\",\n",
      "        \"country\": \"West Indies\",\n",
      "        \"sport\": \"Cricket\"\n",
      "    },\n",
      "    {\n",
      "        \"name\": \"Diego Maradona\",\n",
      "        \"country\": \"Argentina\",\n",
      "        \"sport\": \"Soccer\"\n",
      "    },\n",
      "    {\n",
      "        \"name\": \"Roger Federer\",\n",
      "        \"country\": \"Switzerland\",\n",
      "        \"sport\": \"Tennis\"\n",
      "    },\n",
      "    {\n",
      "        \"name\": \"Ian Thorpe\",\n",
      "        \"country\": \"Australia\",\n",
      "        \"sport\": \"Swimming\"\n",
      "    },\n",
      "    {\n",
      "        \"name\": \"Ronaldo\",\n",
      "        \"country\": \"Brazil\",\n",
      "        \"sport\": \"Soccer\"\n",
      "    },\n",
      "    {\n",
      "        \"name\": \"Usain Bolt\",\n",
      "        \"country\": \"Jamaica\",\n",
      "        \"sport\": \"Running\"\n",
      "    },\n",
      "    {\n",
      "        \"name\": \"P. V. Sindhu\",\n",
      "        \"country\": \"India\",\n",
      "        \"sport\": \"Badminton\"\n",
      "    },\n",
      "    {\n",
      "        \"name\": \"Shane Warne\",\n",
      "        \"country\": \"Australia\",\n",
      "        \"sport\": \"Cricket\"\n",
      "    },\n",
      "    {\n",
      "        \"name\": \"David Beckham\",\n",
      "        \"country\": \"England\",\n",
      "        \"sport\": \"Cricket\"\n",
      "    },\n",
      "    {\n",
      "        \"name\": \"Michael Phelps\",\n",
      "        \"country\": \"USA\",\n",
      "        \"sport\": \"Swimming\"\n",
      "    }\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "!hadoop fs -tail famous_players.json"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef1f2d0d",
   "metadata": {},
   "source": [
    "#### "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b09c3e0e",
   "metadata": {},
   "source": [
    "### 16. Get Disk Free and Disk Usage information in HDFS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "8d5952bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-df [-h] [<path> ...] :\n",
      "  Shows the capacity, free and used space of the filesystem. If the filesystem has\n",
      "  multiple partitions, and no path to a particular partition is specified, then\n",
      "  the status of the root partitions will be shown.\n",
      "                                                                                 \n",
      "  -h  Formats the sizes of files in a human-readable fashion rather than a number\n",
      "      of bytes.                                                                  \n"
     ]
    }
   ],
   "source": [
    "!hadoop fs -help df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b41de50e",
   "metadata": {},
   "source": [
    "#### "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "6db9ffb1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-du [-s] [-h] [-v] [-x] <path> ... :\n",
      "  Show the amount of space, in bytes, used by the files that match the specified\n",
      "  file pattern. The following flags are optional:\n",
      "                                                                                 \n",
      "  -s  Rather than showing the size of each individual file that matches the      \n",
      "      pattern, shows the total (summary) size.                                   \n",
      "  -h  Formats the sizes of files in a human-readable fashion rather than a number\n",
      "      of bytes.                                                                  \n",
      "  -v  option displays a header line.                                             \n",
      "  -x  Excludes snapshots from being counted.                                     \n",
      "  \n",
      "  Note that, even without the -s option, this only shows size summaries one level\n",
      "  deep into a directory.\n",
      "  \n",
      "  The output is in the form \n",
      "  \tsize\tdisk space consumed\tname(full path)\n"
     ]
    }
   ],
   "source": [
    "!hadoop fs -help du"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04703194",
   "metadata": {},
   "source": [
    "#### "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "d16df395",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filesystem                               Size            Used      Available  Use%\n",
      "hdfs://m01.itversity.com:9000  22691948027904  19998119198842  1536160820134   88%\n"
     ]
    }
   ],
   "source": [
    "!hadoop fs -df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "ad60badb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filesystem                       Size    Used  Available  Use%\n",
      "hdfs://m01.itversity.com:9000  20.6 T  18.2 T      1.4 T   88%\n"
     ]
    }
   ],
   "source": [
    "!hadoop fs -df -h"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d45262e",
   "metadata": {},
   "source": [
    "#### "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "e2aef5bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "726663168  2179989504  data/largedeck.txt\n",
      "139239940  417719820   data/nyse_data\n"
     ]
    }
   ],
   "source": [
    "!hadoop fs -du data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "bfce44cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "385.7 K  1.1 M  data_move/nyse_stocks\n",
      "693      2.0 K  data_move/smalldeck.txt\n",
      "1.2 K    3.6 K  data_move/sports\n"
     ]
    }
   ],
   "source": [
    "!hadoop fs -du -h data_move"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fce1c9b6",
   "metadata": {},
   "source": [
    "#### "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acc5bcaf",
   "metadata": {},
   "source": [
    "### 17. Change the Replication Factor of a file in HDFS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "0a49928d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-setrep [-R] [-w] <rep> <path> ... :\n",
      "  Set the replication level of a file. If <path> is a directory then the command\n",
      "  recursively changes the replication factor of all files under the directory tree\n",
      "  rooted at <path>. The EC files will be ignored here.\n",
      "                                                                                 \n",
      "  -w  It requests that the command waits for the replication to complete. This   \n",
      "      can potentially take a very long time.                                     \n",
      "  -R  It is accepted for backwards compatibility. It has no effect.              \n"
     ]
    }
   ],
   "source": [
    "!hadoop fs -help setrep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "3a9b0ce6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 9 items\n",
      "drwx------   - itv005077 supergroup          0 2023-04-15 10:10 .Trash\n",
      "-r--r--r--   3 itv005077 supergroup   29175117 2023-04-16 07:34 address_01_current.json\n",
      "-rw-r--r--   3 itv005077 supergroup   29287626 2020-07-18 14:35 address_06_preserved.json\n",
      "drwxr-xr-x   - itv005077 supergroup          0 2023-04-16 08:25 data\n",
      "drwxr-xr-x   - itv005077 supergroup          0 2023-04-16 08:25 data_move\n",
      "-rw-r--r--   3 itv005077 supergroup       1226 2023-04-16 08:16 famous_players.json\n",
      "-rw-r--r--   3 itv005077 supergroup       5812 2023-04-16 07:48 kv1.txt\n",
      "-rw-r--r--   3 itv005077 supergroup  726663168 2023-04-16 05:18 largedeck.txt\n",
      "-rw-r--r--   3 itv005077 supergroup        693 2023-04-16 05:16 smalldeck.txt\n"
     ]
    }
   ],
   "source": [
    "!hadoop fs -ls "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "ab18394e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Replication 2 set: kv1.txt\n"
     ]
    }
   ],
   "source": [
    "!hadoop fs -setrep 2 kv1.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "83e2f163",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 9 items\n",
      "drwx------   - itv005077 supergroup          0 2023-04-15 10:10 .Trash\n",
      "-r--r--r--   3 itv005077 supergroup   29175117 2023-04-16 07:34 address_01_current.json\n",
      "-rw-r--r--   3 itv005077 supergroup   29287626 2020-07-18 14:35 address_06_preserved.json\n",
      "drwxr-xr-x   - itv005077 supergroup          0 2023-04-16 08:25 data\n",
      "drwxr-xr-x   - itv005077 supergroup          0 2023-04-16 08:25 data_move\n",
      "-rw-r--r--   3 itv005077 supergroup       1226 2023-04-16 08:16 famous_players.json\n",
      "-rw-r--r--   2 itv005077 supergroup       5812 2023-04-16 07:48 kv1.txt\n",
      "-rw-r--r--   3 itv005077 supergroup  726663168 2023-04-16 05:18 largedeck.txt\n",
      "-rw-r--r--   3 itv005077 supergroup        693 2023-04-16 05:16 smalldeck.txt\n"
     ]
    }
   ],
   "source": [
    "!hadoop fs -ls ./"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bd64e8f",
   "metadata": {},
   "source": [
    "#### "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "372fd2af",
   "metadata": {},
   "source": [
    "### 18. Check the file, block and location information of files stored in HDFS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "2d7e7422",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: Use of this script to execute fsck is deprecated.\n",
      "WARNING: Attempting to execute replacement \"hdfs fsck\" instead.\n",
      "\n",
      "Usage: hdfs fsck <path> [-list-corruptfileblocks | [-move | -delete | -openforwrite] [-files [-blocks [-locations | -racks | -replicaDetails | -upgradedomains]]]] [-includeSnapshots] [-showprogress] [-storagepolicies] [-maintenance] [-blockId <blk_Id>] [-replicate]\n",
      "\t<path>\tstart checking from this path\n",
      "\t-move\tmove corrupted files to /lost+found\n",
      "\t-delete\tdelete corrupted files\n",
      "\t-files\tprint out files being checked\n",
      "\t-openforwrite\tprint out files opened for write\n",
      "\t-includeSnapshots\tinclude snapshot data if the given path indicates a snapshottable directory or there are snapshottable directories under it\n",
      "\t-list-corruptfileblocks\tprint out list of missing blocks and files they belong to\n",
      "\t-files -blocks\tprint out block report\n",
      "\t-files -blocks -locations\tprint out locations for every block\n",
      "\t-files -blocks -racks\tprint out network topology for data-node locations\n",
      "\t-files -blocks -replicaDetails\tprint out each replica details \n",
      "\t-files -blocks -upgradedomains\tprint out upgrade domains for every block\n",
      "\t-storagepolicies\tprint out storage policy summary for the blocks\n",
      "\t-maintenance\tprint out maintenance state node details\n",
      "\t-showprogress\tDeprecated. Progress is now shown by default\n",
      "\t-blockId\tprint out which file this blockId belongs to, locations (nodes, racks) of this block, and other diagnostics info (under replicated, corrupted or not, etc)\n",
      "\t-replicate initiate replication work to make mis-replicated\n",
      " blocks satisfy block placement policy\n",
      "\n",
      "Please Note:\n",
      "\n",
      "\t1. By default fsck ignores files opened for write, use -openforwrite to report such files. They are usually  tagged CORRUPT or HEALTHY depending on their block allocation status\n",
      "\t2. Option -includeSnapshots should not be used for comparing stats, should be used only for HEALTH check, as this may contain duplicates if the same file present in both original fs tree and inside snapshots.\n",
      "\n",
      "Generic options supported are:\n",
      "-conf <configuration file>        specify an application configuration file\n",
      "-D <property=value>               define a value for a given property\n",
      "-fs <file:///|hdfs://namenode:port> specify default filesystem URL to use, overrides 'fs.defaultFS' property from configurations.\n",
      "-jt <local|resourcemanager:port>  specify a ResourceManager\n",
      "-files <file1,...>                specify a comma-separated list of files to be copied to the map reduce cluster\n",
      "-libjars <jar1,...>               specify a comma-separated list of jar files to be included in the classpath\n",
      "-archives <archive1,...>          specify a comma-separated list of archives to be unarchived on the compute machines\n",
      "\n",
      "The general command line syntax is:\n",
      "command [genericOptions] [commandOptions]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!hadoop fsck -help"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "8c5b560d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Usage: hdfs fsck <path> [-list-corruptfileblocks | [-move | -delete | -openforwrite] [-files [-blocks [-locations | -racks | -replicaDetails | -upgradedomains]]]] [-includeSnapshots] [-showprogress] [-storagepolicies] [-maintenance] [-blockId <blk_Id>] [-replicate]\n",
      "\t<path>\tstart checking from this path\n",
      "\t-move\tmove corrupted files to /lost+found\n",
      "\t-delete\tdelete corrupted files\n",
      "\t-files\tprint out files being checked\n",
      "\t-openforwrite\tprint out files opened for write\n",
      "\t-includeSnapshots\tinclude snapshot data if the given path indicates a snapshottable directory or there are snapshottable directories under it\n",
      "\t-list-corruptfileblocks\tprint out list of missing blocks and files they belong to\n",
      "\t-files -blocks\tprint out block report\n",
      "\t-files -blocks -locations\tprint out locations for every block\n",
      "\t-files -blocks -racks\tprint out network topology for data-node locations\n",
      "\t-files -blocks -replicaDetails\tprint out each replica details \n",
      "\t-files -blocks -upgradedomains\tprint out upgrade domains for every block\n",
      "\t-storagepolicies\tprint out storage policy summary for the blocks\n",
      "\t-maintenance\tprint out maintenance state node details\n",
      "\t-showprogress\tDeprecated. Progress is now shown by default\n",
      "\t-blockId\tprint out which file this blockId belongs to, locations (nodes, racks) of this block, and other diagnostics info (under replicated, corrupted or not, etc)\n",
      "\t-replicate initiate replication work to make mis-replicated\n",
      " blocks satisfy block placement policy\n",
      "\n",
      "Please Note:\n",
      "\n",
      "\t1. By default fsck ignores files opened for write, use -openforwrite to report such files. They are usually  tagged CORRUPT or HEALTHY depending on their block allocation status\n",
      "\t2. Option -includeSnapshots should not be used for comparing stats, should be used only for HEALTH check, as this may contain duplicates if the same file present in both original fs tree and inside snapshots.\n",
      "\n",
      "Generic options supported are:\n",
      "-conf <configuration file>        specify an application configuration file\n",
      "-D <property=value>               define a value for a given property\n",
      "-fs <file:///|hdfs://namenode:port> specify default filesystem URL to use, overrides 'fs.defaultFS' property from configurations.\n",
      "-jt <local|resourcemanager:port>  specify a ResourceManager\n",
      "-files <file1,...>                specify a comma-separated list of files to be copied to the map reduce cluster\n",
      "-libjars <jar1,...>               specify a comma-separated list of jar files to be included in the classpath\n",
      "-archives <archive1,...>          specify a comma-separated list of archives to be unarchived on the compute machines\n",
      "\n",
      "The general command line syntax is:\n",
      "command [genericOptions] [commandOptions]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!hdfs fsck -help"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "481a1656",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 9 items\n",
      "drwx------   - itv005077 supergroup          0 2023-04-15 10:10 .Trash\n",
      "-r--r--r--   3 itv005077 supergroup   29175117 2023-04-16 07:34 address_01_current.json\n",
      "-rw-r--r--   3 itv005077 supergroup   29287626 2020-07-18 14:35 address_06_preserved.json\n",
      "drwxr-xr-x   - itv005077 supergroup          0 2023-04-16 08:25 data\n",
      "drwxr-xr-x   - itv005077 supergroup          0 2023-04-16 08:25 data_move\n",
      "-rw-r--r--   3 itv005077 supergroup       1226 2023-04-16 08:16 famous_players.json\n",
      "-rw-r--r--   2 itv005077 supergroup       5812 2023-04-16 07:48 kv1.txt\n",
      "-rw-r--r--   3 itv005077 supergroup  726663168 2023-04-16 05:18 largedeck.txt\n",
      "-rw-r--r--   3 itv005077 supergroup        693 2023-04-16 05:16 smalldeck.txt\n"
     ]
    }
   ],
   "source": [
    "!hadoop fs -ls "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "2c948c90",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connecting to namenode via http://m01.itversity.com:9870/fsck?ugi=itv005077&files=1&blocks=1&locations=1&path=%2Fuser%2Fitv005077%2Flargedeck.txt\n",
      "FSCK started by itv005077 (auth:SIMPLE) from /172.16.1.102 for path /user/itv005077/largedeck.txt at Sun Apr 16 08:51:37 EDT 2023\n",
      "\n",
      "/user/itv005077/largedeck.txt 726663168 bytes, replicated: replication=3, 6 block(s):  OK\n",
      "0. BP-1685381103-172.16.1.103-1609223169030:blk_1084670810_10937731 len=134217728 Live_repl=3  [DatanodeInfoWithStorage[172.16.1.106:9866,DS-b1aa8def-bcd8-4514-8697-29c2f7fd008d,DISK], DatanodeInfoWithStorage[172.16.1.107:9866,DS-cc8f7dbb-28ed-477a-b831-7b5d9f146f80,DISK], DatanodeInfoWithStorage[172.16.1.105:9866,DS-6cd19d66-af36-4030-9b5a-8c881ae5efc8,DISK]]\n",
      "1. BP-1685381103-172.16.1.103-1609223169030:blk_1084670811_10937732 len=134217728 Live_repl=3  [DatanodeInfoWithStorage[172.16.1.106:9866,DS-3cdd1a86-1122-4b3f-9d9d-c9fe36cab433,DISK], DatanodeInfoWithStorage[172.16.1.105:9866,DS-cd1d8ab0-7d77-4607-98bf-961a7ad81f45,DISK], DatanodeInfoWithStorage[172.16.1.107:9866,DS-53639da4-6786-42af-a4a6-5021150dddf3,DISK]]\n",
      "2. BP-1685381103-172.16.1.103-1609223169030:blk_1084670813_10937734 len=134217728 Live_repl=3  [DatanodeInfoWithStorage[172.16.1.105:9866,DS-cd1d8ab0-7d77-4607-98bf-961a7ad81f45,DISK], DatanodeInfoWithStorage[172.16.1.107:9866,DS-53639da4-6786-42af-a4a6-5021150dddf3,DISK], DatanodeInfoWithStorage[172.16.1.106:9866,DS-3cdd1a86-1122-4b3f-9d9d-c9fe36cab433,DISK]]\n",
      "3. BP-1685381103-172.16.1.103-1609223169030:blk_1084670814_10937735 len=134217728 Live_repl=3  [DatanodeInfoWithStorage[172.16.1.105:9866,DS-6cd19d66-af36-4030-9b5a-8c881ae5efc8,DISK], DatanodeInfoWithStorage[172.16.1.106:9866,DS-b1aa8def-bcd8-4514-8697-29c2f7fd008d,DISK], DatanodeInfoWithStorage[172.16.1.107:9866,DS-cc8f7dbb-28ed-477a-b831-7b5d9f146f80,DISK]]\n",
      "4. BP-1685381103-172.16.1.103-1609223169030:blk_1084670815_10937736 len=134217728 Live_repl=3  [DatanodeInfoWithStorage[172.16.1.105:9866,DS-cd1d8ab0-7d77-4607-98bf-961a7ad81f45,DISK], DatanodeInfoWithStorage[172.16.1.106:9866,DS-3cdd1a86-1122-4b3f-9d9d-c9fe36cab433,DISK], DatanodeInfoWithStorage[172.16.1.107:9866,DS-53639da4-6786-42af-a4a6-5021150dddf3,DISK]]\n",
      "5. BP-1685381103-172.16.1.103-1609223169030:blk_1084670816_10937737 len=55574528 Live_repl=3  [DatanodeInfoWithStorage[172.16.1.105:9866,DS-6cd19d66-af36-4030-9b5a-8c881ae5efc8,DISK], DatanodeInfoWithStorage[172.16.1.107:9866,DS-cc8f7dbb-28ed-477a-b831-7b5d9f146f80,DISK], DatanodeInfoWithStorage[172.16.1.106:9866,DS-b1aa8def-bcd8-4514-8697-29c2f7fd008d,DISK]]\n",
      "\n",
      "\n",
      "Status: HEALTHY\n",
      " Number of data-nodes:\t3\n",
      " Number of racks:\t\t1\n",
      " Total dirs:\t\t\t0\n",
      " Total symlinks:\t\t0\n",
      "\n",
      "Replicated Blocks:\n",
      " Total size:\t726663168 B\n",
      " Total files:\t1\n",
      " Total blocks (validated):\t6 (avg. block size 121110528 B)\n",
      " Minimally replicated blocks:\t6 (100.0 %)\n",
      " Over-replicated blocks:\t0 (0.0 %)\n",
      " Under-replicated blocks:\t0 (0.0 %)\n",
      " Mis-replicated blocks:\t\t0 (0.0 %)\n",
      " Default replication factor:\t3\n",
      " Average block replication:\t3.0\n",
      " Missing blocks:\t\t0\n",
      " Corrupt blocks:\t\t0\n",
      " Missing replicas:\t\t0 (0.0 %)\n",
      " Blocks queued for replication:\t0\n",
      "\n",
      "Erasure Coded Block Groups:\n",
      " Total size:\t0 B\n",
      " Total files:\t0\n",
      " Total block groups (validated):\t0\n",
      " Minimally erasure-coded block groups:\t0\n",
      " Over-erasure-coded block groups:\t0\n",
      " Under-erasure-coded block groups:\t0\n",
      " Unsatisfactory placement block groups:\t0\n",
      " Average block group size:\t0.0\n",
      " Missing block groups:\t\t0\n",
      " Corrupt block groups:\t\t0\n",
      " Missing internal blocks:\t0\n",
      " Blocks queued for replication:\t0\n",
      "FSCK ended at Sun Apr 16 08:51:37 EDT 2023 in 1 milliseconds\n",
      "\n",
      "\n",
      "The filesystem under path '/user/itv005077/largedeck.txt' is HEALTHY\n"
     ]
    }
   ],
   "source": [
    "!hdfs fsck ./largedeck.txt -files -blocks -locations"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
