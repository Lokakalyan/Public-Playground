{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a6db2d57",
   "metadata": {},
   "outputs": [],
   "source": [
    "import getpass as gp\n",
    "from pyspark.sql import SparkSession, functions as F, types as T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9c224389",
   "metadata": {},
   "outputs": [],
   "source": [
    "user=gp.getuser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "427ce184",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'itv005077'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f7f12b5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession.builder \\\n",
    "    .appName(f'{user}-Week-6-Assignment') \\\n",
    "    .config('spark.sql.warehouse.dir', f'/user/{user}/warehouse') \\\n",
    "    .config('spark.sql.catalogImplementation', 'hive') \\\n",
    "    .enableHiveSupport() \\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "52eb51a7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - hive</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://g02.itversity.com:4040\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.0.1</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>yarn</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>itv005077-Week-6-Assignment</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x7f81d8aa3240>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f352da8",
   "metadata": {},
   "source": [
    "### Question-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "64924205",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = [\n",
    "    (\"Spring\", 12.3),\n",
    "    (\"Summer\", 10.5), \n",
    "    (\"Autumn\", 8.2), \n",
    "    (\"Winter\", 15.1)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "dfe12619",
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = ['season', 'windspeed']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9bfb75b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = spark.createDataFrame(data, columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "983e2afa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- season: string (nullable = true)\n",
      " |-- windspeed: double (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b7926fd3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+---------+\n",
      "|season|windspeed|\n",
      "+------+---------+\n",
      "|Spring|     12.3|\n",
      "|Summer|     10.5|\n",
      "|Autumn|      8.2|\n",
      "|Winter|     15.1|\n",
      "+------+---------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "75cdfcfd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"library_name\": \"Central Library\",\"location\": \"City Center\",\"books\": [{\"book_id\": \"B001\",\"book_name\": \"The Great Gatsby\",\"author\": \"F. Scott Fitzgerald\",\"copies_available\": 5},{\"book_id\": \"B002\",\"book_name\": \"To Kill a Mockingbird\",\"author\": \"Harper Lee\",\"copies_available\": 3}],\"members\": [{\"member_id\": \"M001\",\"member_name\": \"John Smith\",\"age\": 28,\"books_borrowed\": [\"B001\"]},{\"member_id\": \"M002\",\"member_name\": \"Emma Johnson\",\"age\": 35,\"books_borrowed\": []}]},\n",
      "{\"library_name\": \"Community Library\",\"location\": \"Suburb\",\"books\": [{\"book_id\": \"B003\",\"book_name\": \"1984\",\"author\": \"George Orwell\",\"copies_available\": 2},{\"book_id\": \"B004\",\"book_name\": \"Pride and Prejudice\",\"author\": \"Jane Austen\",\"copies_available\": 4}],\"members\": [{\"member_id\": \"M003\",\"member_name\": \"Michael Brown\",\"age\": 42,\"books_borrowed\": [\"B003\",\"B004\"]},{\"member_id\": \"M004\",\"member_name\": \"Sophia Davis\",\"age\": 31,\"books_borrowed\": [\"B004\"]}]}\n"
     ]
    }
   ],
   "source": [
    "!hadoop fs -head /public/trendytech/datasets/library_data.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f4d4e52e",
   "metadata": {},
   "outputs": [],
   "source": [
    "book_schema = T.StructType([\n",
    "    T.StructField('book_id', T.StringType()),\n",
    "    T.StructField('book_name', T.StringType()),\n",
    "    T.StructField('author', T.StringType()),\n",
    "    T.StructField('copies_available', T.IntegerType()),\n",
    "])\n",
    "\n",
    "member_schema = T.StructType([\n",
    "    T.StructField('member_id', T.StringType()),\n",
    "    T.StructField('member_name', T.StringType()),\n",
    "    T.StructField('age', T.IntegerType()),\n",
    "    T.StructField('books_borrowed', T.ArrayType(T.StringType())),\n",
    "])\n",
    "\n",
    "\n",
    "schema = T.StructType([\n",
    "    T.StructField('library_name', T.StringType()),\n",
    "    T.StructField('location', T.StringType()),\n",
    "    T.StructField('books', T.ArrayType(book_schema)),\n",
    "    T.StructField('members', T.ArrayType(member_schema)),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d10e6ddc",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_library = spark.read \\\n",
    "    .format('json') \\\n",
    "    .schema(schema) \\\n",
    "    .load('/public/trendytech/datasets/library_data.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "bfbf7356",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- library_name: string (nullable = true)\n",
      " |-- location: string (nullable = true)\n",
      " |-- books: array (nullable = true)\n",
      " |    |-- element: struct (containsNull = true)\n",
      " |    |    |-- book_id: string (nullable = true)\n",
      " |    |    |-- book_name: string (nullable = true)\n",
      " |    |    |-- author: string (nullable = true)\n",
      " |    |    |-- copies_available: integer (nullable = true)\n",
      " |-- members: array (nullable = true)\n",
      " |    |-- element: struct (containsNull = true)\n",
      " |    |    |-- member_id: string (nullable = true)\n",
      " |    |    |-- member_name: string (nullable = true)\n",
      " |    |    |-- age: integer (nullable = true)\n",
      " |    |    |-- books_borrowed: array (nullable = true)\n",
      " |    |    |    |-- element: string (containsNull = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_library.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0100fb39",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+-----------+------------------------------------------------------------------------------------------------+---------------------------------------------------------------------------+\n",
      "|library_name     |location   |books                                                                                           |members                                                                    |\n",
      "+-----------------+-----------+------------------------------------------------------------------------------------------------+---------------------------------------------------------------------------+\n",
      "|Central Library  |City Center|[[B001, The Great Gatsby, F. Scott Fitzgerald, 5], [B002, To Kill a Mockingbird, Harper Lee, 3]]|[[M001, John Smith, 28, [B001]], [M002, Emma Johnson, 35, []]]             |\n",
      "|Community Library|Suburb     |[[B003, 1984, George Orwell, 2], [B004, Pride and Prejudice, Jane Austen, 4]]                   |[[M003, Michael Brown, 42, [B003, B004]], [M004, Sophia Davis, 31, [B004]]]|\n",
      "+-----------------+-----------+------------------------------------------------------------------------------------------------+---------------------------------------------------------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_library.show(truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "317bfd40",
   "metadata": {},
   "source": [
    "### Question-2:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "eebcafdb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_number,train_name,seats_available,passenger_name,age,ticket_number,seat_number\n",
      "123,Express,100,John,25,T123,A1\n",
      "123,Express,100,Emma,30,T124,B2\n",
      "456,Superfast,150,Michael,35,T125,C3\n",
      "456,Superfast,150,Sophia,40,T126,D4\n",
      "789,Local,50,William,28,T127,E5\n",
      "789,Local,50,Sophia,32,T128,F6\n",
      "789,Local,50,Oliver,45,T129,G7\n"
     ]
    }
   ],
   "source": [
    "!hadoop fs -head /public/trendytech/datasets/train.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3ffdcc71",
   "metadata": {},
   "outputs": [],
   "source": [
    "schema = 'train_number int, train_name string, seats_available int, passenger_name string, age int, ticket_number string, seat_number string'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7a0da7ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = spark.read \\\n",
    "    .format('csv') \\\n",
    "    .option('header', 'true') \\\n",
    "    .schema(schema) \\\n",
    "    .load('/public/trendytech/datasets/train.csv')    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "adcb51fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- train_number: integer (nullable = true)\n",
      " |-- train_name: string (nullable = true)\n",
      " |-- seats_available: integer (nullable = true)\n",
      " |-- passenger_name: string (nullable = true)\n",
      " |-- age: integer (nullable = true)\n",
      " |-- ticket_number: string (nullable = true)\n",
      " |-- seat_number: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_train.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2b0b01ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+----------+---------------+--------------+---+-------------+-----------+\n",
      "|train_number|train_name|seats_available|passenger_name|age|ticket_number|seat_number|\n",
      "+------------+----------+---------------+--------------+---+-------------+-----------+\n",
      "|         123|   Express|            100|          John| 25|         T123|         A1|\n",
      "|         123|   Express|            100|          Emma| 30|         T124|         B2|\n",
      "|         456| Superfast|            150|       Michael| 35|         T125|         C3|\n",
      "|         456| Superfast|            150|        Sophia| 40|         T126|         D4|\n",
      "|         789|     Local|             50|       William| 28|         T127|         E5|\n",
      "+------------+----------+---------------+--------------+---+-------------+-----------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_train.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "08b43e97",
   "metadata": {},
   "outputs": [],
   "source": [
    "drop_cols = ['passenger_name', 'age']\n",
    "df_train = df_train.drop(*drop_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "2ed43543",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+----------+---------------+-------------+-----------+\n",
      "|train_number|train_name|seats_available|ticket_number|seat_number|\n",
      "+------------+----------+---------------+-------------+-----------+\n",
      "|         123|   Express|            100|         T123|         A1|\n",
      "|         123|   Express|            100|         T124|         B2|\n",
      "|         456| Superfast|            150|         T125|         C3|\n",
      "|         456| Superfast|            150|         T126|         D4|\n",
      "|         789|     Local|             50|         T127|         E5|\n",
      "+------------+----------+---------------+-------------+-----------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_train.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "6c6b5ce1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dups_col = ['train_number', 'ticket_number']\n",
    "df_train.dropDuplicates(dups_col).count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "55d914fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+\n",
      "|train_name|\n",
      "+----------+\n",
      "|   Express|\n",
      "|     Local|\n",
      "| Superfast|\n",
      "+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_train.select('train_name').distinct().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "23d9ef88",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"store_id\": 1, \"product\": \"Apple\", \"quantity\": 10, \"revenue\": 100.0}\n",
      "{\"store_id\": 2, \"product\": \"Banana\", \"quantity\": 15, \"revenue\": 75.0}\n",
      "{\"store_id\": 3, \"product\": \"Orange\", \"quantity\": 12, \"revenue\": 90.0}\n",
      "{\"store_id\": 4, \"product\": \"Mango\", \"quantity\": 8, \"revenue\": 120.0}\n",
      "{\"store_id\": 5, \"product\": \"Grape\", \"quantity\": 20, \"revenue\": 150.0}\n",
      "{\"store_id\": 6, \"product\": \"Watermelon\", \"quantity\": 5, \"revenue\": 50.0}\n",
      "{\"store_id\": 7, \"product\": \"Strawberry\", \"quantity\": 18, \"revenue\": 108.0}\n",
      "{\"store_id\": 8, \"product\": \"Pineapple\", \"quantity\": 14, \"revenue\": 140.0}\n",
      "{\"store_id\": 9, \"product\": \"Cherry\", \"quantity\": 7, \"revenue\": 105.0}\n",
      "{\"store_id\": 10, \"product\": \"Pear\", \"quantity\": 9, \"revenue\": 81.0}\n",
      "{\"store_id\": 11, \"product\": \"Blueberry\", \"quantity\": 11, \"revenue\": 88.0}\n",
      "{\"store_id\": 12, \"product\": \"Kiwi\", \"quantity\": 16, \"revenue\": 128.0}\n",
      "{\"store_id\": 13, \"product\": \"Peach\", \"quantity\": 13, \"revenue\": 91.0}\n",
      "{\"store_id\": 14, \"product\": \"Plum\", \"quantity\": 6, \"revenue\": 54.0}\n",
      "{\"store_id\": 15, \"product\": \"Lemon\", \"quantity\": 10, \"revenue\": 70.0}\n",
      "{\"store_id\": 16, \"product\": \"Raspberry\", \"quantity\": 17, \"revenue\": 136.0}\n",
      "{\"store_id\": 17, \"product\": \"Coconut\", \"quantity\": 4, \"revenue\": 80.0}\n",
      "{\"store_id\": 18, \"product\": \"Avocado\", \"quantity\": 11, \"revenue\": 99.0}\n",
      "{\"store_id\": 19, \"product\": \"Blackberry\", \"quantity\": 8, \"revenue\": 64.0}\n",
      "{\"store_id\": 20, \"product\": \"G\", \"quantity\": \"Invalid\", \"revenue\": \"NaN\"}\n",
      "{\"store_id\": 21, \"product\": \"Pineapple\", \"quantity\": 14, \"revenue\": 140.0\n",
      "{\"store_id\": 22, \"product\": \"Watermelon\", \"quantity\": 5, \"revenue\": \"Invalid\"}\n"
     ]
    }
   ],
   "source": [
    "!hadoop fs -cat /public/trendytech/datasets/sales_data.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "9e889bdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "schema = T.StructType([\n",
    "    T.StructField('store_id', T.IntegerType()),\n",
    "    T.StructField('product', T.StringType()),\n",
    "    T.StructField('quantity', T.IntegerType()),\n",
    "    T.StructField('revenue', T.FloatType()),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "e2e1e01c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sales = spark.read \\\n",
    "    .format('json') \\\n",
    "    .schema(schema) \\\n",
    "    .option('mode', 'permissive') \\\n",
    "    .load('/public/trendytech/datasets/sales_data.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "1c8be687",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- store_id: integer (nullable = true)\n",
      " |-- product: string (nullable = true)\n",
      " |-- quantity: integer (nullable = true)\n",
      " |-- revenue: float (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_sales.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "d70215dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+----------+--------+-------+\n",
      "|store_id|   product|quantity|revenue|\n",
      "+--------+----------+--------+-------+\n",
      "|       1|     Apple|      10|  100.0|\n",
      "|       2|    Banana|      15|   75.0|\n",
      "|       3|    Orange|      12|   90.0|\n",
      "|       4|     Mango|       8|  120.0|\n",
      "|       5|     Grape|      20|  150.0|\n",
      "|       6|Watermelon|       5|   50.0|\n",
      "|       7|Strawberry|      18|  108.0|\n",
      "|       8| Pineapple|      14|  140.0|\n",
      "|       9|    Cherry|       7|  105.0|\n",
      "|      10|      Pear|       9|   81.0|\n",
      "|      11| Blueberry|      11|   88.0|\n",
      "|      12|      Kiwi|      16|  128.0|\n",
      "|      13|     Peach|      13|   91.0|\n",
      "|      14|      Plum|       6|   54.0|\n",
      "|      15|     Lemon|      10|   70.0|\n",
      "|      16| Raspberry|      17|  136.0|\n",
      "|      17|   Coconut|       4|   80.0|\n",
      "|      18|   Avocado|      11|   99.0|\n",
      "|      19|Blackberry|       8|   64.0|\n",
      "|      20|         G|    null|    NaN|\n",
      "|    null|      null|    null|   null|\n",
      "|      22|Watermelon|       5|   null|\n",
      "+--------+----------+--------+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_sales.show(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "843c5894",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "22"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_sales.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "418e0170",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sales_dropmalformed = spark.read \\\n",
    "    .format('json') \\\n",
    "    .schema(schema) \\\n",
    "    .option('mode', 'dropmalformed') \\\n",
    "    .load('/public/trendytech/datasets/sales_data.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "7557f9df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+----------+--------+-------+\n",
      "|store_id|product   |quantity|revenue|\n",
      "+--------+----------+--------+-------+\n",
      "|1       |Apple     |10      |100.0  |\n",
      "|2       |Banana    |15      |75.0   |\n",
      "|3       |Orange    |12      |90.0   |\n",
      "|4       |Mango     |8       |120.0  |\n",
      "|5       |Grape     |20      |150.0  |\n",
      "|6       |Watermelon|5       |50.0   |\n",
      "|7       |Strawberry|18      |108.0  |\n",
      "|8       |Pineapple |14      |140.0  |\n",
      "|9       |Cherry    |7       |105.0  |\n",
      "|10      |Pear      |9       |81.0   |\n",
      "|11      |Blueberry |11      |88.0   |\n",
      "|12      |Kiwi      |16      |128.0  |\n",
      "|13      |Peach     |13      |91.0   |\n",
      "|14      |Plum      |6       |54.0   |\n",
      "|15      |Lemon     |10      |70.0   |\n",
      "|16      |Raspberry |17      |136.0  |\n",
      "|17      |Coconut   |4       |80.0   |\n",
      "|18      |Avocado   |11      |99.0   |\n",
      "|19      |Blackberry|8       |64.0   |\n",
      "+--------+----------+--------+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_sales_dropmalformed.show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "58199601",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "21"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_sales_dropmalformed.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "f78859e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 12 items\n",
      "drwxr-xr-x   - itv005857 supergroup          0 2023-05-18 17:40 /public/trendytech/datasets/customer_nested\n",
      "-rw-r--r--   3 itv005857 supergroup       1319 2023-05-23 13:04 /public/trendytech/datasets/hospital.csv\n",
      "-rw-r--r--   3 itv005857 supergroup        925 2023-05-23 13:05 /public/trendytech/datasets/library_data.json\n",
      "drwxr-xr-x   - itv005857 supergroup          0 2023-05-28 04:30 /public/trendytech/datasets/orders\n",
      "-rw-r--r--   3 itv005857 supergroup    7064041 2023-05-04 07:46 /public/trendytech/datasets/orders.json\n",
      "-rw-r--r--   3 itv005857 supergroup        292 2023-05-18 10:50 /public/trendytech/datasets/orders_sample1.csv\n",
      "-rw-r--r--   3 itv005857 supergroup        292 2023-05-18 10:50 /public/trendytech/datasets/orders_sample2.csv\n",
      "-rw-r--r--   3 itv005857 supergroup        296 2023-05-18 10:50 /public/trendytech/datasets/orders_sample3.csv\n",
      "drwxr-xr-x   - itv005857 supergroup          0 2023-05-04 07:54 /public/trendytech/datasets/ordersorc\n",
      "drwxr-xr-x   - itv005857 supergroup          0 2023-05-04 07:58 /public/trendytech/datasets/ordersparquet\n",
      "-rw-r--r--   3 itv005857 supergroup       1602 2023-05-23 13:05 /public/trendytech/datasets/sales_data.json\n",
      "-rw-r--r--   3 itv005857 supergroup        324 2023-05-23 13:04 /public/trendytech/datasets/train.csv\n"
     ]
    }
   ],
   "source": [
    "!hadoop fs -ls /public/trendytech/datasets/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "22f35064",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "patient_id,admission_date,discharge_date,diagnosis,doctor_id,total_cost\n",
      "1,01-01-2022,2022-01-10,Pneumonia,101,5000.00\n",
      "2,02-05-2022,2022-02-09,Appendicitis,102,7000.00\n",
      "3,03-12-2022,2022-03-18,Fractured Arm,103,3500.00\n",
      "4,04-02-2022,2022-04-08,Heart Attack,104,15000.00\n",
      "5,05-05-2022,2022-05-07,Influenza,105,2500.00\n",
      "6,06-10-2022,2022-06-15,Appendicitis,106,8000.00\n",
      "7,07-20-2022,2022-07-25,Pneumonia,107,5500.00\n",
      "8,08-25-2022,2022-09-01,Heart Attack,108,20000.00\n",
      "9,09-15-2022,2022-09-22,Fractured Leg,109,6000.00\n",
      "10,10-05-2022,2022-10-10,Appendicitis,110,7500.00\n",
      "11,11-02-2022,2022-11-05,Influenza,111,2800.00\n",
      "12,12-10-2022,2022-12-18,Pneumonia,112,6000.00\n",
      "13,01-02-2023,2023-01-09,Heart Attack,113,18000.00\n",
      "14,02-14-2023,2023-02-18,Appendicitis,114,7200.00\n",
      "15,03-20-2023,2023-03-28,Fractured Arm,115,3800.00\n",
      "16,04-05-2023,2023-04-11,Influenza,116,2700.00\n",
      "17,05-08-2023,2023-05-11,Heart Attack,117,16000.00\n",
      "18,06-15-2023,2023-06-20,Pneumonia,118,4800.00\n",
      "19,07-22-2023,2023-07-27,Fractured Leg,119,6500.00\n",
      "20,0"
     ]
    }
   ],
   "source": [
    "!hadoop fs -head /public/trendytech/datasets/hospital.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "e3886044",
   "metadata": {},
   "outputs": [],
   "source": [
    "schema = T.StructType([\n",
    "    T.StructField('patient_id', T.IntegerType()),\n",
    "    T.StructField('admission_date', T.StringType()),\n",
    "    T.StructField('discharge_date', T.DateType()),\n",
    "    T.StructField('diagnosis', T.StringType()),\n",
    "    T.StructField('doctor_id', T.IntegerType()),\n",
    "    T.StructField('total_cost', T.FloatType()),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "68a97933",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_patient = spark.read \\\n",
    "    .format('csv') \\\n",
    "    .option('header', 'true') \\\n",
    "    .schema(schema) \\\n",
    "    .load('/public/trendytech/datasets/hospital.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "846eb721",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- patient_id: integer (nullable = true)\n",
      " |-- admission_date: string (nullable = true)\n",
      " |-- discharge_date: date (nullable = true)\n",
      " |-- diagnosis: string (nullable = true)\n",
      " |-- doctor_id: integer (nullable = true)\n",
      " |-- total_cost: float (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_patient.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "85098dc0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+--------------+--------------+-------------+---------+----------+\n",
      "|patient_id|admission_date|discharge_date|    diagnosis|doctor_id|total_cost|\n",
      "+----------+--------------+--------------+-------------+---------+----------+\n",
      "|         1|    01-01-2022|    2022-01-10|    Pneumonia|      101|    5000.0|\n",
      "|         2|    02-05-2022|    2022-02-09| Appendicitis|      102|    7000.0|\n",
      "|         3|    03-12-2022|    2022-03-18|Fractured Arm|      103|    3500.0|\n",
      "|         4|    04-02-2022|    2022-04-08| Heart Attack|      104|   15000.0|\n",
      "|         5|    05-05-2022|    2022-05-07|    Influenza|      105|    2500.0|\n",
      "|         6|    06-10-2022|    2022-06-15| Appendicitis|      106|    8000.0|\n",
      "|         7|    07-20-2022|    2022-07-25|    Pneumonia|      107|    5500.0|\n",
      "|         8|    08-25-2022|    2022-09-01| Heart Attack|      108|   20000.0|\n",
      "|         9|    09-15-2022|    2022-09-22|Fractured Leg|      109|    6000.0|\n",
      "|        10|    10-05-2022|    2022-10-10| Appendicitis|      110|    7500.0|\n",
      "|        11|    11-02-2022|    2022-11-05|    Influenza|      111|    2800.0|\n",
      "|        12|    12-10-2022|    2022-12-18|    Pneumonia|      112|    6000.0|\n",
      "|        13|    01-02-2023|    2023-01-09| Heart Attack|      113|   18000.0|\n",
      "|        14|    02-14-2023|    2023-02-18| Appendicitis|      114|    7200.0|\n",
      "|        15|    03-20-2023|    2023-03-28|Fractured Arm|      115|    3800.0|\n",
      "|        16|    04-05-2023|    2023-04-11|    Influenza|      116|    2700.0|\n",
      "|        17|    05-08-2023|    2023-05-11| Heart Attack|      117|   16000.0|\n",
      "|        18|    06-15-2023|    2023-06-20|    Pneumonia|      118|    4800.0|\n",
      "|        19|    07-22-2023|    2023-07-27|Fractured Leg|      119|    6500.0|\n",
      "|        20|    08-10-2023|    2023-08-16| Appendicitis|      120|    7800.0|\n",
      "+----------+--------------+--------------+-------------+---------+----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_patient.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "c9f97330",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_patient = df_patient.withColumn('admission_date', F.to_date('admission_date', 'MM-dd-yyyy'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "f11c8769",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- patient_id: integer (nullable = true)\n",
      " |-- admission_date: date (nullable = true)\n",
      " |-- discharge_date: date (nullable = true)\n",
      " |-- diagnosis: string (nullable = true)\n",
      " |-- doctor_id: integer (nullable = true)\n",
      " |-- total_cost: float (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_patient.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "9bd304d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+--------------+--------------+-------------+---------+----------+\n",
      "|patient_id|admission_date|discharge_date|    diagnosis|doctor_id|total_cost|\n",
      "+----------+--------------+--------------+-------------+---------+----------+\n",
      "|         1|    2022-01-01|    2022-01-10|    Pneumonia|      101|    5000.0|\n",
      "|         2|    2022-02-05|    2022-02-09| Appendicitis|      102|    7000.0|\n",
      "|         3|    2022-03-12|    2022-03-18|Fractured Arm|      103|    3500.0|\n",
      "|         4|    2022-04-02|    2022-04-08| Heart Attack|      104|   15000.0|\n",
      "|         5|    2022-05-05|    2022-05-07|    Influenza|      105|    2500.0|\n",
      "|         6|    2022-06-10|    2022-06-15| Appendicitis|      106|    8000.0|\n",
      "|         7|    2022-07-20|    2022-07-25|    Pneumonia|      107|    5500.0|\n",
      "|         8|    2022-08-25|    2022-09-01| Heart Attack|      108|   20000.0|\n",
      "|         9|    2022-09-15|    2022-09-22|Fractured Leg|      109|    6000.0|\n",
      "|        10|    2022-10-05|    2022-10-10| Appendicitis|      110|    7500.0|\n",
      "|        11|    2022-11-02|    2022-11-05|    Influenza|      111|    2800.0|\n",
      "|        12|    2022-12-10|    2022-12-18|    Pneumonia|      112|    6000.0|\n",
      "|        13|    2023-01-02|    2023-01-09| Heart Attack|      113|   18000.0|\n",
      "|        14|    2023-02-14|    2023-02-18| Appendicitis|      114|    7200.0|\n",
      "|        15|    2023-03-20|    2023-03-28|Fractured Arm|      115|    3800.0|\n",
      "|        16|    2023-04-05|    2023-04-11|    Influenza|      116|    2700.0|\n",
      "|        17|    2023-05-08|    2023-05-11| Heart Attack|      117|   16000.0|\n",
      "|        18|    2023-06-15|    2023-06-20|    Pneumonia|      118|    4800.0|\n",
      "|        19|    2023-07-22|    2023-07-27|Fractured Leg|      119|    6500.0|\n",
      "|        20|    2023-08-10|    2023-08-16| Appendicitis|      120|    7800.0|\n",
      "+----------+--------------+--------------+-------------+---------+----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_patient.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "66eed213",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_patient = df_patient \\\n",
    "    .drop('doctor_id') \\\n",
    "    .withColumnRenamed('total_cost', 'hospital_bill') \\\n",
    "    .withColumn('duration_of_stay', F.datediff('discharge_date', 'admission_date'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "5e7ad9bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+--------------+--------------+-------------+-------------+----------------+\n",
      "|patient_id|admission_date|discharge_date|    diagnosis|hospital_bill|duration_of_stay|\n",
      "+----------+--------------+--------------+-------------+-------------+----------------+\n",
      "|         1|    2022-01-01|    2022-01-10|    Pneumonia|       5000.0|               9|\n",
      "|         2|    2022-02-05|    2022-02-09| Appendicitis|       7000.0|               4|\n",
      "|         3|    2022-03-12|    2022-03-18|Fractured Arm|       3500.0|               6|\n",
      "|         4|    2022-04-02|    2022-04-08| Heart Attack|      15000.0|               6|\n",
      "|         5|    2022-05-05|    2022-05-07|    Influenza|       2500.0|               2|\n",
      "|         6|    2022-06-10|    2022-06-15| Appendicitis|       8000.0|               5|\n",
      "|         7|    2022-07-20|    2022-07-25|    Pneumonia|       5500.0|               5|\n",
      "|         8|    2022-08-25|    2022-09-01| Heart Attack|      20000.0|               7|\n",
      "|         9|    2022-09-15|    2022-09-22|Fractured Leg|       6000.0|               7|\n",
      "|        10|    2022-10-05|    2022-10-10| Appendicitis|       7500.0|               5|\n",
      "|        11|    2022-11-02|    2022-11-05|    Influenza|       2800.0|               3|\n",
      "|        12|    2022-12-10|    2022-12-18|    Pneumonia|       6000.0|               8|\n",
      "|        13|    2023-01-02|    2023-01-09| Heart Attack|      18000.0|               7|\n",
      "|        14|    2023-02-14|    2023-02-18| Appendicitis|       7200.0|               4|\n",
      "|        15|    2023-03-20|    2023-03-28|Fractured Arm|       3800.0|               8|\n",
      "|        16|    2023-04-05|    2023-04-11|    Influenza|       2700.0|               6|\n",
      "|        17|    2023-05-08|    2023-05-11| Heart Attack|      16000.0|               3|\n",
      "|        18|    2023-06-15|    2023-06-20|    Pneumonia|       4800.0|               5|\n",
      "|        19|    2023-07-22|    2023-07-27|Fractured Leg|       6500.0|               5|\n",
      "|        20|    2023-08-10|    2023-08-16| Appendicitis|       7800.0|               6|\n",
      "+----------+--------------+--------------+-------------+-------------+----------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_patient.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "09e54ae3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_patient = df_patient \\\n",
    "    .withColumn('adjusted_total', \n",
    "                F.expr(\n",
    "                    'case when diagnosis == \"Heart Attack\" then hospital_bill * 1.5 \\\n",
    "                          when diagnosis == \"Appendicitis\" then hospital_bill * 1.2 \\\n",
    "                    else hospital_bill end'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "f9bb714b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+--------------+--------------+-------------+-------------+----------------+--------------+\n",
      "|patient_id|admission_date|discharge_date|    diagnosis|hospital_bill|duration_of_stay|adjusted_total|\n",
      "+----------+--------------+--------------+-------------+-------------+----------------+--------------+\n",
      "|         1|    2022-01-01|    2022-01-10|    Pneumonia|       5000.0|               9|        5000.0|\n",
      "|         2|    2022-02-05|    2022-02-09| Appendicitis|       7000.0|               4|        8400.0|\n",
      "|         3|    2022-03-12|    2022-03-18|Fractured Arm|       3500.0|               6|        3500.0|\n",
      "|         4|    2022-04-02|    2022-04-08| Heart Attack|      15000.0|               6|       22500.0|\n",
      "|         5|    2022-05-05|    2022-05-07|    Influenza|       2500.0|               2|        2500.0|\n",
      "|         6|    2022-06-10|    2022-06-15| Appendicitis|       8000.0|               5|        9600.0|\n",
      "|         7|    2022-07-20|    2022-07-25|    Pneumonia|       5500.0|               5|        5500.0|\n",
      "|         8|    2022-08-25|    2022-09-01| Heart Attack|      20000.0|               7|       30000.0|\n",
      "|         9|    2022-09-15|    2022-09-22|Fractured Leg|       6000.0|               7|        6000.0|\n",
      "|        10|    2022-10-05|    2022-10-10| Appendicitis|       7500.0|               5|        9000.0|\n",
      "|        11|    2022-11-02|    2022-11-05|    Influenza|       2800.0|               3|        2800.0|\n",
      "|        12|    2022-12-10|    2022-12-18|    Pneumonia|       6000.0|               8|        6000.0|\n",
      "|        13|    2023-01-02|    2023-01-09| Heart Attack|      18000.0|               7|       27000.0|\n",
      "|        14|    2023-02-14|    2023-02-18| Appendicitis|       7200.0|               4|        8640.0|\n",
      "|        15|    2023-03-20|    2023-03-28|Fractured Arm|       3800.0|               8|        3800.0|\n",
      "|        16|    2023-04-05|    2023-04-11|    Influenza|       2700.0|               6|        2700.0|\n",
      "|        17|    2023-05-08|    2023-05-11| Heart Attack|      16000.0|               3|       24000.0|\n",
      "|        18|    2023-06-15|    2023-06-20|    Pneumonia|       4800.0|               5|        4800.0|\n",
      "|        19|    2023-07-22|    2023-07-27|Fractured Leg|       6500.0|               5|        6500.0|\n",
      "|        20|    2023-08-10|    2023-08-16| Appendicitis|       7800.0|               6|        9360.0|\n",
      "+----------+--------------+--------------+-------------+-------------+----------------+--------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_patient.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "1f8d3615",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-------------+-------------+--------------+\n",
      "|patient_id|    diagnosis|hospital_bill|adjusted_total|\n",
      "+----------+-------------+-------------+--------------+\n",
      "|         1|    Pneumonia|       5000.0|        5000.0|\n",
      "|         2| Appendicitis|       7000.0|        8400.0|\n",
      "|         3|Fractured Arm|       3500.0|        3500.0|\n",
      "|         4| Heart Attack|      15000.0|       22500.0|\n",
      "|         5|    Influenza|       2500.0|        2500.0|\n",
      "|         6| Appendicitis|       8000.0|        9600.0|\n",
      "|         7|    Pneumonia|       5500.0|        5500.0|\n",
      "|         8| Heart Attack|      20000.0|       30000.0|\n",
      "|         9|Fractured Leg|       6000.0|        6000.0|\n",
      "|        10| Appendicitis|       7500.0|        9000.0|\n",
      "|        11|    Influenza|       2800.0|        2800.0|\n",
      "|        12|    Pneumonia|       6000.0|        6000.0|\n",
      "|        13| Heart Attack|      18000.0|       27000.0|\n",
      "|        14| Appendicitis|       7200.0|        8640.0|\n",
      "|        15|Fractured Arm|       3800.0|        3800.0|\n",
      "|        16|    Influenza|       2700.0|        2700.0|\n",
      "|        17| Heart Attack|      16000.0|       24000.0|\n",
      "|        18|    Pneumonia|       4800.0|        4800.0|\n",
      "|        19|Fractured Leg|       6500.0|        6500.0|\n",
      "|        20| Appendicitis|       7800.0|        9360.0|\n",
      "+----------+-------------+-------------+--------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "cols = [\"patient_id\", \"diagnosis\", \"hospital_bill\", \"adjusted_total\"]\n",
    "df_patient.select(*cols).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "c2694c7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.stop()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Pyspark 3",
   "language": "python",
   "name": "pyspark3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
